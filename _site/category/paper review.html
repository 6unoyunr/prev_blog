<!DOCTYPE html><html><head> <!-- Include Meta Tags Here --><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta http-equiv="X-UA-Compatible" content="ie=edge"><meta name="viewport" content="width=device-width, height=device-height, initial-scale=1 user-scalable=no, shrink-to-fit=no"><meta content='#000000' name='theme-color'/><meta name="keywords" content="AI, Developer, Research engineer"><title>Welcome to my blog | PAPER REVIEW</title><!-- Open Graph general (Facebook, Pinterest & Google+) --><meta name="og:title" content="Welcome to my blog | PAPER REVIEW"><meta name="og:description" content="Personal Tech Blog"><meta name="og:image" content=""><meta name="og:image:alt" content="Welcome to my blog | PAPER REVIEW"><meta name="og:url" content="http://localhost:4000/category/paper%20review"><meta name="article:author" content="https://www.facebook.com/"><meta name="og:site_name" content="Welcome to my blog | PAPER REVIEW"><meta name="og:type" content="website"> <!-- Twitter --><meta property="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Welcome to my blog | PAPER REVIEW"><meta name="twitter:description" content="Personal Tech Blog"><meta name="twitter:site" content="@"><meta name="twitter:creator" content="@"><meta name="twitter:image:src" content=""> <!-- Search Engine --><meta name="description" content="Personal Tech Blog"><meta name="image" content=""> <!-- Schema.org for Google --><meta itemprop="name" content="Welcome to my blog | PAPER REVIEW"><meta name="author" content="JY"/><meta itemprop="description" content="Personal Tech Blog"><meta itemprop="image" content=""> <!-- Global site tag (gtag.js) - Google Analytics --> <script async src="https://www.googletagmanager.com/gtag/js?id=G-KFNS88G1GM"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'G-KFNS88G1GM'); </script><title>Welcome to my blog</title><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href=/assets/external/font-awesome-4.7.0/css/font-awesome.css><link rel="stylesheet" href="/assets/css/style_dark.css"><link rel="stylesheet" href="/assets/css/style.css"> <script src="https://kit.fontawesome.com/6a97161b76.js" crossorigin="anonymous"></script> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5834956759419182" crossorigin="anonymous"></script><link rel="apple-touch-icon" sizes="180x180" href="/assets/logo.ico/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/logo.ico/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/logo.ico/favicon-16x16.png"><link rel="mask-icon" href="/assets/logo.ico/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#FFFFFF"></head><body><nav class="navbar is-black is-fixed-top" role="navigation" aria-label="main navigation" id="navbar"><div class="container"> <!-- logo or branding image on left side --><div class="navbar-brand"> <a class="navbar-item" href="http://localhost:4000/"> <strong>Welcome to my blog</strong> </a><div class="navbar-burger" data-target="navbar-menu"> <span></span> <span></span> <span></span></div></div><!-- children of navbar-menu must be navbar-start and/or navbar-end --><div class="navbar-menu has-background-black" id="navbar-menu"><div class="navbar-end"> <a class="navbar-item " href="http://localhost:4000/">HOME</a> <a class="navbar-item" href="http://localhost:4000/#about">ABOUT</a> <a class="navbar-item" href="http://localhost:4000/#contact">CONTACT</a> <a class="navbar-item " href="http://localhost:4000/cv">CV</a> <a class="navbar-item " href="http://localhost:4000/blog">POST</a><div class="navbar-item has-dropdown is-hoverable"> <a class="navbar-link"> CATEGORY </a><div class="navbar-dropdown has-background-black is-left"> <a href="http://localhost:4000/category/deep%20learning" class="navbar-item has-text-grey-light "> DEEP LEARNING </a> <a href="http://localhost:4000/category/development" class="navbar-item has-text-grey-light "> DEVELOPMENT </a> <a href="http://localhost:4000/category/github%20blog" class="navbar-item has-text-grey-light "> GITHUB BLOG </a> <a href="http://localhost:4000/category/paper%20review" class="navbar-item has-text-grey-light is-active"> PAPER REVIEW </a> <!--<hr class="navbar-divider"> <a class="navbar-item"> Report an issue </a> --></div></div><input id="darkmode_switch" class="mh_toogle" type="checkbox"> <label for="darkmode_switch" class="material-icons-sharp mh_toggle_btn"></label></div></div></div></nav><!-- Bulma Navbar JS --> <script> document.addEventListener('DOMContentLoaded', function () { /* Get all "navbar-burger" elements */ var $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0); /* Check if there are any navbar burgers */ if ($navbarBurgers.length > 0) { /* Add a click event on each of them */ $navbarBurgers.forEach(function ($el) { $el.addEventListener('click', function () { /* Get the target from the "data-target" attribute */ var target = $el.dataset.target; var $target = document.getElementById(target); /* Toggle the class on both the "navbar-burger" and the "navbar-menu" */ $el.classList.toggle('is-active'); $target.classList.toggle('is-active'); }); }); } }); </script> <script> /* 스타일 파일들 */ const defaultTheme = [...document.styleSheets].find(style => /(style.css)$/.test(style.href)); const darkTheme = [...document.styleSheets].find(style => /(style_dark.css)$/.test(style.href)); /* 스위치, 현재 테마 상태 불러오기 */ let mode = document.getElementById("darkmode_switch"); const current = localStorage.theme; /* 기존 상태에 따라 스위치 체크해주기 */ mode.checked = current === 'dark'; /* 체크된 거에 따라서 스타일 지정해주기 */ darkTheme.disabled = mode.checked !== true; defaultTheme.disabled = mode.checked === true; mode.addEventListener('click', function(){ localStorage.theme = mode.checked ? 'dark' : 'light'; darkTheme.disabled = mode.checked !== true; defaultTheme.disabled = mode.checked === true; }); </script><section class="hero is-fullheight" id="blog"><div class="hero-body"><div class="container"> <!-- Main container --><nav class="level has-text-centered"> <!-- Left side --><div class="level-left"><p class="subtitle is-uppercase has-text-weight-medium has-text-grey">Deep Learning Paper 🗞</p></div><!-- Right side --><div class="level-right"><div class="level-item"><div class="field has-addons has-text-weight-medium has-text-grey" id="search"><p class="control"> <input id="search-input" class="input is-shadowless is-uppercase has-text-grey has-text-weight-normal" type="text" placeholder="Search Here"></p><p class="control"> <button class="button"> <i class="fa fa-search has-text-grey"></i> </button></p></div></div></div></nav></div></div><div id="results-container"></div><!--Blog Cards Section--><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://github.com/user-attachments/assets/c6d8358d-db2c-4c0a-8d45-7b881a8f26d7);"></div></div><a href="http://localhost:4000/blog/deepseekr1"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">딥시크(Deepseek)-R1에 대한 고찰. Thinking about Deepseek-R1 with Reinforcement Learning(RL).</h1><div class="content has-text-grey"> A Little Bit Personal들어가기전 극히 개인적인 주저리나는 아직도 공부를 한다. 대부분의 개발자는 커리어를 쌓으며 끊임없는 공부가 필요한데, 왜냐하면 지금까지 익혀온 기술 스택이 더이상 트렌디하지 않아지는 경우가 많기 때문이다. 특히나 AI의 경우에는 빠른 변화를 보이는데, 그래서 그런지 실제로 논문을 쓰다가 미친 일반화 성능을 보이는 파운데이션 모델이 나와버리면 해당 task가 ...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">February 02, 2025</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">19 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://github.com/user-attachments/assets/dfab1904-b168-484d-945e-1b290b232f89);"></div></div><a href="http://localhost:4000/blog/mamba"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Mamba modeling의 기초 (3) - Linear-Time Sequence Modeling with Selective State Spaces (Mamba)에 대하여</h1><div class="content has-text-grey"> 시작하기 전에 …이전 글들을 올린 후 꽤나 많은 시간이 지났다. 처음으로 올렸던 글인 LSSL(Linear State-Space Layer)에서는 연속 시퀀스 데이터셋에 대해 딥러닝 모델이 효과적으로 latent space를 정의할 수 있는 구조의 발달 양상을 살펴보았다. 그 중 가장 주요한 키포인트가 되는 HiPPO 논문의 경우 임의의 길이를 가지는 시퀀스의 hidden state를 모...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">September 20, 2024</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">13 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://github.com/user-attachments/assets/2d5f8fa6-13c4-4132-b2d7-6c7661277216);"></div></div><a href="http://localhost:4000/blog/s4"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Mamba modeling의 기초 (2) - (S4) Efficiently Modeling Long Sequences with Structured State Spaces에 대하여</h1><div class="content has-text-grey"> 시작하기 전에,HiPPO는 SSM 구조에서 Long-term range를 구축하기 위한 matrix $A$ 구조의 중요성을 언급하였고, LSSL에서는 SSM을 연속적으로 존재하는 $A$ 전부에 대해 이를 일반화하였다. 이전 글에서 Mamba modeling의 기초가 되는 LSSL에 대해서 설명했었고, 해당 글에 간단한 수식과 관련된 증명을 첨부했었다. 솔직한 심정을 담아 말해보자면, 아직 본인은 이러한 기본 내용들을 전부 이해하지 못했다고 생각하고 있고 이 글을 통해서 맘바를 이...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">July 22, 2024</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">17 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://github.com/user-attachments/assets/0b8e20dc-51ff-4183-aa83-4e85f721e82c);"></div></div><a href="http://localhost:4000/blog/lssl"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Mamba modeling의 기초 (1) - Linear State-Space Layer (LSSL)에 대하여</h1><div class="content has-text-grey"> 연속 데이터 구조에 대한 DNN의 발전Sequential한 데이터를 처리하기 위해 딥러닝 모델은 수많은 변화와 발전을 이루었다. 그 중 요즘 대표적으로 LLM 및 multimodal 연구에서 활발하게 활용되는 것은 Transformer 구조이지만, 그 이전에는 LSTM이나 GRU같이 Long term(거리가 먼 문맥 간의 ...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">February 01, 2024</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">21 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://github.com/user-attachments/assets/2589c893-6551-45d5-9d15-6113ae611fe0);"></div></div><a href="http://localhost:4000/blog/dino2"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">DINOv2(Learning Robust Visual Features without Supervision) 논문 리뷰</h1><div class="content has-text-grey"> Supervised 학습의 한계점이전 게시글 중 DINO에서는 Self-supervised learning은 NLP 뿐만 아니라 CV에서도 적절한 전략을 잘 사용한다면 기존 ViT/CNN 구조에서 발견하지 못한 유의미한 visual feature를 획득할 수 있음이 증명되었다는 점을 소개했었다. Supervised learning은 lab...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 04, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">9 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://github.com/user-attachments/assets/2589c893-6551-45d5-9d15-6113ae611fe0);"></div></div><a href="http://localhost:4000/blog/dino"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">DINO(Emerging Properties in Self-Supervised Vision Transformers) 논문 리뷰</h1><div class="content has-text-grey"> 들어가며 …제목에서 알 수 있듯이 이 논문은 Vision Transformer가 자기 학습을 통해 습득할 수 있는 능력이나 특성에 대해 논의한다. ViT의 프레임워크가 제안된 배경에는 자연어 분야의 Transformer 구조가 존재하는데, 이미 GPT나 BERT와 같은 후속 연구를 기반으로 NLP에서는 Large Dataset의 self-supervised learning이 downstream task에서 보다 풍부한 se...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">November 12, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">12 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://github.com/user-attachments/assets/5b746dea-64fb-4ead-a987-8615bde81855);"></div></div><a href="http://localhost:4000/blog/continual"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Continual learning/Lifelong learning의 개념과 방법론 총정리</h1><div class="content has-text-grey"> 이 글은 survey 논문인 A Comprehensive Survey of Continual Learning: Theory, Method and Application를 각색 및 요약한 글입니다.Continual Learning 이란?인공지능과 유기체의 근본적 차...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">September 01, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">27 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://github.com/user-attachments/assets/8a5c2ea9-2139-4d10-8032-30ef8f1ff824);"></div></div><a href="http://localhost:4000/blog/meru"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">MERU(Hyperbolic Image-Text Representations) 논문 리뷰</h1><div class="content has-text-grey"> 들어가며…논문을 소개하기 전, CLIP과 ALIGN과 같은 기존 Vision-Language Modeling의 문제점을 짚는 것이 우선이다. 만약 두 논문에 대한 사전 지식이 없다면 MERU 라는 이름을 가지는 이 모델이 문제시하고자 했던 유클리디안 space(모든 datapoint에 대해 동일한 거리 기준을 삼는 것)에 대한 이해를 하기 힘들기 때문에 적어도 본인...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">July 12, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">12 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235696115-4385adb1-d0a7-4fed-8f5a-af3e36e7851e.gif);"></div></div><a href="http://localhost:4000/blog/glide"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">GLIDE(Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models) 논문 및 코드 리뷰</h1><div class="content has-text-grey"> 들어가며최근 DDPM 수식 조지기 게시글과 더불어 DDIM 등등 여러 diffusion model 관련 논문들을 리뷰했었다. 그 중 diffusion에 condition을 추가하는 논문인 cla...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">May 02, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">20 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235468213-09aaeaec-4cd4-4503-8e67-6b279557a6d5.png);"></div></div><a href="http://localhost:4000/blog/controlnet"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">ControlNet 논문 이해하기 및 사용해보기</h1><div class="content has-text-grey"> 들어가며ControlNet의 논문 제목 풀네임은 ‘Adding conditional control to text-to-image diffusion models’이다. 이른바 ControlNet이라고 불리는 이번 연구는 사전 학습된 large diffusion model을 어떻게 하면 input condition에 맞게 효율적인 knowledge transfer이 가능할지에 대해 논의한 페이퍼이다. Diffusion model이라는...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">May 01, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">10 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235350592-1e8e47d9-7d84-48bc-b0eb-b8d2a499600b.gif);"></div></div><a href="http://localhost:4000/blog/diffusionpapers"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Improved DDPM + Diffusion beats GAN + Classifier free diffusion guidance 논문 리뷰</h1><div class="content has-text-grey"> 들어가며…이번에 리뷰할 논문은 총 3개 시리즈로, 전체적으로 디퓨전 모델(DDPM, DDIM)에 기반하여 작성되었다는 점이 공통점이고, 모두 diffusion model의 sampling quality를 높이기 위한 노력으로 이어진다고 볼 수 있다. 그 중 Improved DDPM의 경우 DDPM에서 가장 baseline 실험만 진행된 점에 추가로 몇몇의 modificat...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">April 30, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">27 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/234610703-89f369d0-0008-4b8a-8207-d93263dd09a8.gif);"></div></div><a href="http://localhost:4000/blog/consistency"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Consistency models 논문 리뷰</h1><div class="content has-text-grey"> 들어가며…Yang Song씨의 논문은 항상 읽다보면 피가 말린다. 안그래도 수식이 방대한 딥러닝 세상에서 더욱 수식을 멋지게 활용(?)하여 Appendix를 화려하게 채워주기 때문이다. 바로 이전에 리뷰했던 논문인 score based diffusion의 기초 논문들 중 하나인 ‘Score-based ge...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">April 26, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">18 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/233842820-ef7d8900-8b01-4d28-9aad-50851829da2c.gif);"></div></div><a href="http://localhost:4000/blog/scoresde"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Score-based generative modeling through stochastic differential equations 이해하기</h1><div class="content has-text-grey"> 들어가며 …오늘 리뷰할 논문은 Score based generative modeling을 continous variable SDE로 풀어낸 논문이며, diffusion based approach 중 가장 유명한 DDPM과 더불어 디퓨전 기초 논문이라고 불리는 녀석이다(근데 난이도로 봐서는 기초는 아닌 것 같음). DDPM과 결을 달리하는 부분은 sampling 방식에서 numerical하게 미분 방정식을 푼다는 점이고 단계적 예...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">April 22, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">17 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/233400307-1d80a1f0-e737-40c9-96ee-2844b7473d3a.gif);"></div></div><a href="http://localhost:4000/blog/ddim"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">DDIM(Denoising Diffusion Implicit Models) 이해하기</h1><div class="content has-text-grey"> 들어가며 …DDPM은 adversarial training과 같이 직접 latent prior를 지정해줄 수 없는 GAN 모델과는 다르게 collapse가 발생하지 않고 안정적인 학습이 가능하다는 장점을 통해 generative model의 새로운 기대주로 떠오를 수 있었다.그러나 DDPM의 경우 학습 시 많은 iteration($T = 1000$)을 거치면서 아주 작은 가우시안 노이즈를 픽셀 별로 더하고, 각 step에 대한 noised i...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">April 20, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">11 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/232323912-84c15e40-ee39-4783-aea4-b3880fcf3dfa.gif);"></div></div><a href="http://localhost:4000/blog/DDPMproof"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">DDPM 수식 증명만 죄다 조져버리기</h1><div class="content has-text-grey"> 들어가며…정말 수식 증명만 조지는 내용이라 DDPM 자체에 대한 내용은 이전 글을 참고하면 좋다(참고 링크). 근데 지금보니까 저 글을 쓸때도 완벽하게 이해하고 쓴 건 아닌 것 같다는 생각.. DDPM 논문 링크는 여기. 이 어려운 벌써 논문이 3년이나 됐나 싶다.&lt;h1 id=&quot;forward-and-r...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">April 02, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">10 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/228143473-e28161a7-2ec0-4322-bf1b-9f617ab48a6d.gif);"></div></div><a href="http://localhost:4000/blog/parameterfree"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Parameter-free Online Test-time adaptation 논문 리뷰</h1><div class="content has-text-grey"> 딥러닝 연구의 한계점State-of-the-art(SOTA)인 vision model을 학습하는 것은 연구 목적으로 사용할 때나, 실제 사업에 활용할 때 모두 cost가 많이 드는 작업에 해당된다.심지어 최근 연구 경향을 보면 알 수 있듯이 보다 resource를 많이 사용하여(네트워크 크기나 데이터셋의 규모 모두에 해당) 다양한 분야에서 뛰어난 성능을 보여주기 시작했다. 하지만 일반적으로 NVIDIA나 Adobe researc...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">March 28, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">23 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/227496551-8a7c2609-6841-4801-810b-da6a9fbfd0a5.gif);"></div></div><a href="http://localhost:4000/blog/ContrastiveTTA"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Contrastive test time adaptation 논문 리뷰</h1><div class="content has-text-grey"> 딥러닝 : Representation을 효율적으로 학습하는 법제목에서도 볼 수 있듯이 Test-time adaptation이라는 task가 해당 paper의 main이다. 바로 본론으로 들어가기 전에 잠시 언급하고 싶은 내용은, 딥러닝은 네트워크가 특정 데이터셋의 representation을 잘 학습하도록 하고, 학습된 representation을 feature map으로 사용하여 목적이 되는 task를 해결하고자 하는 ...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">March 24, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">12 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/224949257-fb9f95ca-4f2b-4817-bb10-000b5cb7cecb.gif);"></div></div><a href="http://localhost:4000/blog/tent"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">TENT, Continual test-time adaptation(CoTTA) 논문 리뷰</h1><div class="content has-text-grey"> 들어가며 …최근 test time domain adaptation에 대한 논문이 많이 나오는 중이다. 본인이 판단했을 때 TTA(Test time adaptation) 혹은 TTDA(Test time domain adaptation)이 활발하게 연구된 이유는 다음과 같다.첫번째 이유는 UDA같이 수많은 연구가 진행된 쪽으로는 더이상 성능 mining이 쉽지 않다. 요 며칠간 UDA와...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">March 14, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">19 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/222342311-c0bd6df0-834f-4cde-9cab-e3988aa57c29.gif);"></div></div><a href="http://localhost:4000/blog/CoCa"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">CoCa - Contrastive Captioners are Image-Text Foundation Models 논문 리뷰</h1><div class="content has-text-grey"> 들어가며…여러 task에서 대용량의 데이터셋으로 large-scale pretrained network를 학습하는 이유는 다양한 downstream tasks에 학습된 representation을 빠르게 적용하기 위함이고, 이를 딥러닝에서는 representation transfer 혹은 knowledge transfer 관점에서 접근한다. 리뷰할 &lt;a href=&quot;https://arxiv.org/pd...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">March 01, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">9 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/222030729-fc5d7460-8d26-4d6a-a1a8-fbc71131c9f1.gif);"></div></div><a href="http://localhost:4000/blog/ffalgorithm2"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">딥러닝의 체계를 바꾼다! The Forward-Forward Algorithm 논문 리뷰 (2)</h1><div class="content has-text-grey"> 들어가며…이번 포스트는 바로 이전에 작성된 글인 FF(Forward-forward algorithm) 소개글(참고 링크)에 이어 Hinton이라는 저자가 FF 알고리즘의 학습을 contrastive learning과 연관지어 설명한 부분을 자세히 다뤄보고자 작성하게 되었다.&lt;h1 id=&quot;hinton의-rbmrestricted-boltzmann-machine에-대...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">February 27, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">20 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/221447149-7ed12c39-a466-4f34-82d8-cecd13e304ef.gif);"></div></div><a href="http://localhost:4000/blog/ffalgorithm"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">딥러닝의 체계를 바꾼다! The Forward-Forward Algorithm 논문 리뷰 (1)</h1><div class="content has-text-grey"> 들어가며…제목이 너무 어그로성이 짙었는데, 논문에서는 backpropagation을 완전히 대체하는 알고리즘을 소개한 것은 아니고 딥러닝의 새로운 연구 방향을 잡아준 것과 같다.이 논문에서는 neural network를 학습하는 기존 방법들로부터 벗어나 새로운 학습법을 소개한다. 새롭게 제시된 방법인 FF(forward-forward) 알고리즘은 뒤에서 보다 디테일하게 언급되겠지만 Supervised learning과 unsuper...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">February 22, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">29 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/219937038-7277341b-efd1-4391-8ab3-12fa5cbc9f01.gif);"></div></div><a href="http://localhost:4000/blog/CoOp"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Prompt learning in Vision-Language(CoOp, CoCoOp) 논문 리뷰</h1><div class="content has-text-grey"> 들어가며…대용량의 pre-trained VL model(CLIP, ALIGN 등등)은 여러 downstream task에서 효과적으로 representation을 transfer할 수 있음을 보여주었다. 특히 zero-shot이나 linear probing에서 보여준 성능은 vision과 language를 함께 활용하는 것이 보다 open world set에 대해 적합한 학습 구조라는 것을 증명하였다. 대부분 one-hot encoding과 같은 disc...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">February 19, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">19 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/218607574-b22c5c47-40e7-475a-ace9-4d265c854d6a.gif);"></div></div><a href="http://localhost:4000/blog/BLIP"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Bootstrapping Language-Image Pre-training(BLIP, BLIP2) 논문 리뷰</h1><div class="content has-text-grey"> BLIP을 제시한 이유기존에 많이 살펴보았던 CLIP과 같이 vision과 language의 multimodality를 활용한 학습을 Vision-Language Pre-training(VLP)이라고 부른다. 그러나 기존 VLP의 학습 형태는 understanding based task(Encoding을 통해 downstream task를 해결하는 구조) 혹은 generation based task(Decoding을 통해 특정 modality를 ...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">February 14, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">20 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/217227526-9d8ff3cc-1d07-4a22-9ddc-4d7fdbc07f54.gif);"></div></div><a href="http://localhost:4000/blog/dreamfield"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Zero-shot Text-Guided Object Generation with Dream Fields에 대하여</h1><div class="content has-text-grey"> 들어가며 …이 논문에서 가장 핵심이 되는 키워드만 따로 생각해보면, text representation을 통해 학습된 multi-modal image 관계를 사용하여 3D object를 렌더링하는 것이다. 3D generation 혹은 rendering의 경우 획득이 비교적 간단한 데이터셋인 이미지와는 다르게 captioning된 3D dataset이 필요하다. 이는 3D generation network로 하여금 한정된 갯수(pool)의 categor...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">February 07, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">26 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/215319341-b7c913a7-26c9-4bc4-bab9-a19281714eeb.gif);"></div></div><a href="http://localhost:4000/blog/styleclip+styleganada"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">(StyleCLIP, StyleGAN-NADA) CLIP based image manipulation에 대하여</h1><div class="content has-text-grey"> StyleGANStyleGAN의 등장은 사실상 생성 모델을 style based approach로 해석한 첫번째 논문이라고 볼 수 있다. StyleGAN 논문을 이 글에서 자세히 설명하지는 않겠지만 가볍게 요약하자면, constant vector로 표현된 하나의 feature map 도화지가 있고($4 \times 4 \times 512$), 이 도화지에 latent vector로부터 추출된 st...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">January 29, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">22 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/214473940-413c366a-cf7d-4431-883e-64ae6097be86.png);"></div></div><a href="http://localhost:4000/blog/maskclip"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">MaskCLIP 논문 리뷰</h1><div class="content has-text-grey"> 들어가며…사실 리뷰할 MaskCLIP은 ECCV paper와 arxiv paper 두 종류가 있다. 논문 제목은 다르지만 main idea의 제목이 같다보니 조금 혼란스러운 감이 없지 않아 있었다. 처음에 읽고 싶었던 논문은 ‘Extract Free Dense Labels from CLIP‘이며, 그 다음에 추가로 arxiv에 올라온 논문 제목은 ‘&lt;a href=&quot;https://arxiv.org/abs...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">January 24, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">10 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/213900254-5da22304-43ab-457c-9533-0927b0d859df.png);"></div></div><a href="http://localhost:4000/blog/clip"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">CLIP(Learning transferable visual models from natural language supervision)에 대하여</h1><div class="content has-text-grey"> What is modality?논문 소개에 앞서 multimodal이라는 의미에 대해 짚고 넘어가기 위해 먼저 ‘modality’의 의미에 대해 확인해보자. 일반적으로 modality가 가지는 의미는 크거나 작게 구분이 가능하다. 만약 확률 분포에 대해서 생각해보면, modality는 하나의 probability density function를 나타내며, 이때 multimodal은 서로 다른 peak(local maxima)를 ...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">January 22, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">20 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/210159076-23125484-b1a0-40a4-a676-23518861a952.gif);"></div></div><a href="http://localhost:4000/blog/gangeal"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">About GAN supervsed alignment(GAN-gealing)</h1><div class="content has-text-grey"> 논문 요약 및 소개이번에 소개할 논문은 이번에 연구실에서 논문을 준비하면서 여러 생성 모델 분야에 대해서 살펴보다가 흥미있게 봤던 GAN-supervised learning이다. 이전 리뷰들은 여러 논문들을 전반적으로 살펴봤었는데, 이번에는 이 논문 하나만 집중해서 볼 예정이다. 사실 이름만 봐서는 단순히 generative network를 학습하는 것처럼 느껴지지만, GAN-s...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">January 01, 2023</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">14 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235353492-2ca621c9-8091-4c8a-b852-39195e45928b.gif);"></div></div><a href="http://localhost:4000/blog/trnmultimodal"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Transformer와 Multimodal에 대하여</h1><div class="content has-text-grey"> Convolutional neural network의 발전기존의 딥러닝에서 사용되던 대부분의 네트워크 구조는 Multilayer perceptron(MLP) 혹은 Convolutional neural network(CNN)이 주를 이루고 있었다. 단순히 modality를 $1 \times N$ 차원 벡터로 늘려서 연산하는 MLP와는 다르게 Convolutional neural network 구조는 image와 같...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 21, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">39 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235353456-8461d395-cb9d-4471-8208-d72754519f4c.jpg);"></div></div><a href="http://localhost:4000/blog/lowshot"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Low shot learning에 대하여</h1><div class="content has-text-grey"> 일반적으로 네트워크를 학습시킬 때, 대량의 데이터를 통해 최적의 parameter를 찾는 과정을 생각하게 된다. 그러나 만약 inference에 사용될 데이터셋에 대한 학습 데이터가 없거나 부족하다면, 네트워크는 적은 데이터로도 충분히 최적화될 수 있어야한다. 여기서 출발한 개념이 바로 ‘Low-shot learning’이며, 여기서의 ‘shot’은 네트워크에게 제공되는 학습 데이터셋을 의미한다.Few shot learning&lt;...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 20, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">14 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://github.com/user-attachments/assets/102ccb32-36a3-4034-94fc-74ef6856b1b4);"></div></div><a href="http://localhost:4000/blog/transfer"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">다양한 Deep learning 학습법</h1><div class="content has-text-grey"> 이번 게시물은 딥러닝 네트워크를 학습시킬 수 있는 다양한 학습법에 대한 내용이다. 단순히 단일 task에 대한 학습법이 아니라 다양한 환경에서 적용될 수 있는 방법론에 대해서 다루기 때문에 이번 게시글에는 다양한 내용을 담게 되었다. 그래서 우선 글을 본격적으로 시작하기 전에 어떤 내용을 다룰 것인지 간단하게 소개를 하고 시작하도록 하겠다. Transfer learning : DL optimization in different tasks Knowledge distillati...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 18, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">24 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235353385-c4e8a00d-85dc-461b-9f50-c0a543d53e38.gif);"></div></div><a href="http://localhost:4000/blog/graphnn"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">그래프를 활용한 neural network</h1><div class="content has-text-grey"> 우리가 지금까지 봐왔던 전반적인 모델들의 특징은, 따로 설명하지는 않았지만 데이터셋 전체에 대해 i.i.d(independent and identically distribution)을 가정한다. 즉 어떠한 modality에 대해 얻어진 데이터셋 각각은 서로 독립적으로 존재하며, 어떠한 추론 과정에서도 다른 데이터셋에 의한 영향을 받지 않는다는 의미가 된다. 이번에 살펴볼 graph를 통한 neural network의 접근은 이와 차이가 있다.그래프란?...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 17, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">18 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235353241-4dfff373-a961-4d00-966a-46f8356692dc.png);"></div></div><a href="http://localhost:4000/blog/imagemanipulate"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">GAN을 활용한 이미지 조작(image to image 그리고 GAN inversion까지)</h1><div class="content has-text-grey"> Generative model인 GAN은 여러 방면에서 활용될 수 있다. 대표적인 Image synthesis(합성)의 경우 Texture synthesis(PSGAN, TextureGAN, &lt;a ...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 12, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">14 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235353087-1d8c492f-1caf-45c9-b160-d1fd96e656ee.png);"></div></div><a href="http://localhost:4000/blog/gan2"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">GAN variations(DCGAN, CGAN, PGGAN and StyleGAN)에 대하여</h1><div class="content has-text-grey"> DCGAN: Unsupervised Representation Learning with Deep Convolutional Generative Adversarial NetworksGAN(Generative Adversarial Network)에 대해서는 이미 기존에 다룬 적이 있다. 간단하게 요약하자면 생성자인 genera...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 11, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">14 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235353010-a64c9794-7dd9-4656-a691-fa99127f6e0c.gif);"></div></div><a href="http://localhost:4000/blog/gan"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Generative adversarial networks(GAN)에 대하여</h1><div class="content has-text-grey"> 이번 게시글에서는 생성 모델 중 하나인 GAN(Generative Adversarial Networks)에 대해 다룰 예정이다. 앞서 다른 생성 모델들인 VAE, Diffusion에 대해서는 모두 소개했었는데 가장 유명하고 가장 많이 연구된 GAN을 빼먹었다는게 아쉬워서 들고 왔다. GAN 연구는 여전히 활발히 진행 중이며 StyleGAN과 같이 스타일에 따른 이미지 생성 모델 뿐만 아니라 3D scene aware GAN이나 depth map generation 등 다양한 분야에서 활용되고 있다. GAN이 가장 좋은 점...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 09, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">11 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235352966-2120920e-4d5f-4f2a-830b-97ebeddca9bc.jpg);"></div></div><a href="http://localhost:4000/blog/light"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">About light weight CNNs(MobileNet 시리즈들)</h1><div class="content has-text-grey"> 경량화 네트워크Deep learning의 발전은 하드웨어와 함께 시작되었고, 충분히 좋은 성능을 가지는 CPU 혹은 GPU 없이는 뛰어난 추론 능력을 가진 네트워크를 fully 활용할 수 없는 것이 사실이다. 그러나 언제까지나 무거운 서버컴에서 딥러닝을 돌릴 순 없기 때문에 딥러닝 네트워크의 경량화, 간소화가 필수적이다. &lt;img src=&quot;https://user-images.githubusercontent...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 08, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">7 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235352897-15e29b3f-ad6b-4063-898e-0a6bb468347a.png);"></div></div><a href="http://localhost:4000/blog/efficient"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Efficient deep neural networks에 대하여</h1><div class="content has-text-grey"> Efficient Network딥러닝 네트워크를 구성하는데 있어서 고려해야할 점은, 학습에 사용될 dataset의 크기나 특성 그리고 궁극적으로 해결하고자 하는 task일 것이다. 그리고 이러한 것들을 모두 신경쓰고도 최종적으로 확인해야할 부분은, 내가 가진 resource(GPU와 같은 장비)를 사용해서 학습이 가능한가?라고 볼 수 있다. 만약 누군가 우리에게 외주를 맡겼다고 가정해보자. 학습 가능한 GPU 성능도 있고, 굳이 저용량의 모바일 기기...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 08, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">8 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235352836-99c2a2ef-1197-4bb2-a730-1e48fcf60ded.jpg);"></div></div><a href="http://localhost:4000/blog/mixmatchpaper"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">MixMatch-A holistic approach to semi-supervised learning에 대하여</h1><div class="content has-text-grey"> 준지도학습이란 흔히 일부 레이블이 존재하는 데이터에 대해 학습한 모델을 토대로 레이블이 없는 데이터셋에 대해서 학습을 진행하는 것을 의미한다. 즉, unsupervised learning과 동일하게 representation mapping을 어떠한 방식으로 해결할 것인지에 대한 분석이 중요하며, 본 게시글에서는 SSL(Semi-supervised learning)에서 가장 성능을 끌어올렸던 유명한 논문 중 하나인 MixMatch에 대해 리뷰하도록 하겠다. &lt;a href=&quot;https://arxiv.org/abs/1905.0...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 07, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">11 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235352743-df5ada36-38de-4154-becd-d8be1fbf1732.gif);"></div></div><a href="http://localhost:4000/blog/nsvf"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">NSVF-Neural Sparse Voxel Fields에 대해서</h1><div class="content has-text-grey"> NSVFNeural Sparse Voxel Fields Abstract사실적인 형태의 real-world scen...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 06, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">8 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235352726-336ebcfe-adc7-4592-a247-a84b439b9432.jpg);"></div></div><a href="http://localhost:4000/blog/nerf"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">NeRF-Representing Scene as Neural Radiance Fields for View Synthesis에 대해서</h1><div class="content has-text-grey"> Mildenhall, Ben, et al. “Nerf: Representing scenes as neural radiance fields for view synthesis.” Communications of the ACM 65.1 (2021): 99-106.Abstract이 논문은 input으로 한정된 수의 3D scene을 획득, 이를 활용하여...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 05, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">18 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/220251868-6804a167-f742-41f7-ae6e-03fbb25d9dac.gif);"></div></div><a href="http://localhost:4000/blog/InfoNCEpaper"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Simple explanation of NCE(Noise Contrastive Estimation) and InfoNCE</h1><div class="content has-text-grey"> 해당 내용은 Representation Learning with Contrastive Predictive Coding에서 소개된 InfoNCE를 기준으로 그 loss term의 시작에 있는 InfoNCE에 대해 간단한 설명을 하고자 작성하게 되었다. 논문링크InfoNCE는 contrastive learning의 기본에 있는 연구가 되며, 흔히 multimodal(멀티모달)이라 불리는 AI의 새로운 지평을 열기 위해 보다 다...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">December 02, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">18 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/235352656-046154f5-8abc-4434-bbcd-c48f4b4ad0b5.gif);"></div></div><a href="http://localhost:4000/blog/DDPM"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Denoising diffusion probabilistic model에 대해서</h1><div class="content has-text-grey"> Denoising Diffusion Probabilistic Model(DDPM)Score matching networkDiffusion model은 score matching network로부터 나왔다고 한다. 그렇다면 대체 score matching network는 무엇일까? &lt;img src=&quot;ht...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">November 28, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">13 min</span> read</div></div></a></div><div class="columns has-text-centered" id="blog-card" name="blogcards"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url(https://user-images.githubusercontent.com/79881119/218650013-9378f36f-59e8-447b-8ba3-018f3d65b16f.gif);"></div></div><a href="http://localhost:4000/blog/VAE"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">Variational autoencoder에 대해서</h1><div class="content has-text-grey"> Variational AutoEncoder(VAE)Deep generative learning 딥러닝을 배제하고 무언가를 생성하는 모델을 생각해보자. 그 무언...<hr class="has-background-grey"> <span class="has-text-grey">Published on <span class="has-text-weight-semibold">November 24, 2022</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">12 min</span> read</div></div></a></div></div></section><br> <!--Footer begins here--><footer id="footer"> <!--Footer Button--><div class="container has-text-centered has-background-grey-darker" id="backtotop"> <a class="has-text-white" onclick="window.scroll(0,0)">BACK TO TOP</a></div><!--Footer Main Section--><div class="has-background-grey-darker"><div class="container columns"> <!--Name Section--><div class="column has-text-left-desktop has-text-centered-mobile"> <a href="http://localhost:4000/#about"><div class="columns"><div class="column is-one-fifth-desktop is-one-fifth-fullhd is-one-quarter-tablet"><figure class="image is-64x64"> <img class="is-rounded" src="https://avatars.githubusercontent.com/u/201962047?v=4"></figure></div><div class="column is-marginless"><h5 class="has-text-grey-lighter">JY</h5><div class="content has-text-grey"><p>I am an AI researcher with a strong interest in machine learning and dee...</p></div></div></div></a></div><!--Link Section--><div class="column has-text-white"><h3>More Links</h3><li> <a href="http://localhost:4000/category/development">DEVELOPMENT</a></li><li> <a href="http://localhost:4000/category/github%20blog">GITHUB BLOG</a></li><li> <a href="http://localhost:4000/category/paper%20review">PAPER REVIEW</a></li></div><!--Blog-post Section--><div class="column has-text-white"><h3>Recent Posts</h3><li> <a href="http://localhost:4000/blog/deepseekr1">딥시크(Deepseek)-R1에 대한 고찰. Thinking about Deepseek-R1 with Reinforcement Learning(RL).</a></li><li> <a href="http://localhost:4000/blog/mamba">Mamba modeling의 기초 (3) - Linear-Time Sequence Modeling with Selective State Spaces (Mamba)에 대하여</a></li><li> <a href="http://localhost:4000/blog/s4">Mamba modeling의 기초 (2) - (S4) Efficiently Modeling Long Sequences with Structured State Spaces에 대하여</a></li></div></div></div><div class="has-background-black has-text-centered has-text-white" id="credits"></div></footer><script src="http://localhost:4000/assets/js/simple-jekyll-search.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search'), resultsContainer: document.getElementById('results-container'), json: 'http://localhost:4000/search.json', searchResultTemplate: '<div style="border: 0.15rem dashed black" class="searchResult columns has-text-centered" id="blog-card"><div class="column is-marginless is-paddingless is-one-third-desktop is-one-third-fullhd is-one-third-tablet"><div class="image is-16by9" style="background-image: url({image});"></div></div><a href="{url}"><div class="column has-text-left-desktop has-text-left-tablet"><h1 class="title is-size-4-touch">{title}</h1><div class="content has-text-grey">{content}<hr class="has-background-grey"><span class="has-text-grey">Published on <span class="has-text-weight-semibold">{date}</span></span> | <i class="fa fa-clock"></i> <span class="has-text-weight-semibold">{readtime} min</span> read</div></div></a></div>', noResultsText: '<div class="subtitle has-text-centered is-uppercase">No Results Found</div><hr class="has-background-black" style="margin: 0.5rem 5rem 2.5rem 5rem">', fuzzy: true, }); </script></body></html><script> let cards = document.getElementsByName("blogcards"); cards.forEach((card) => { let cardmiddle = (card.getBoundingClientRect().top + card.getBoundingClientRect().bottom)/2.0; if(cardmiddle <= 120 || cardmiddle >= window.innerHeight-120){ card.style.opacity = 0.1; } else{ card.style.opacity = 1.0; } }); window.addEventListener("scroll", (event)=> { cards.forEach((card) => { let cardmiddle = (card.getBoundingClientRect().top + card.getBoundingClientRect().bottom)/2.0; if(cardmiddle <= 120 || cardmiddle >= window.innerHeight-120){ card.style.opacity = 0.1; } else{ card.style.opacity = 1.0; } }); }); </script>

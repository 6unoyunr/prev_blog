<!DOCTYPE html><html><head><head> <!-- Include Meta Tags Here --><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta http-equiv="X-UA-Compatible" content="ie=edge"><meta name="viewport" content="width=device-width, height=device-height, initial-scale=1 user-scalable=no, shrink-to-fit=no"><meta content='#000000' name='theme-color'/><meta name="keywords" content="AI, Developer, Research engineer"><title>Welcome to my blog | cs231n 내용 요약 (4) - Backpropagation</title><!-- Open Graph general (Facebook, Pinterest & Google+) --><meta name="og:title" content="Welcome to my blog | cs231n 내용 요약 (4) - Backpropagation"><meta name="og:description" content="Lecture summary"><meta name="og:image" content="https://github.com/user-attachments/assets/cdb8f444-3819-448c-868e-03e4fabb4dcc"><meta name="og:image:alt" content="Welcome to my blog | cs231n 내용 요약 (4) - Backpropagation"><meta name="og:url" content="http://localhost:4000/blog/cs231n04"><meta name="article:author" content="https://www.facebook.com/"><meta name="og:site_name" content="Welcome to my blog | cs231n 내용 요약 (4) - Backpropagation"><meta name="og:type" content="website"> <!-- Twitter --><meta property="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Welcome to my blog | cs231n 내용 요약 (4) - Backpropagation"><meta name="twitter:description" content="Lecture summary"><meta name="twitter:site" content="@"><meta name="twitter:creator" content="@"><meta name="twitter:image:src" content="https://github.com/user-attachments/assets/cdb8f444-3819-448c-868e-03e4fabb4dcc"> <!-- Search Engine --><meta name="description" content="Lecture summary"><meta name="image" content="https://github.com/user-attachments/assets/cdb8f444-3819-448c-868e-03e4fabb4dcc"> <!-- Schema.org for Google --><meta itemprop="name" content="Welcome to my blog | cs231n 내용 요약 (4) - Backpropagation"><meta name="author" content="JY"/><meta itemprop="description" content="Lecture summary"><meta itemprop="image" content="https://github.com/user-attachments/assets/cdb8f444-3819-448c-868e-03e4fabb4dcc"><title>Welcome to my blog</title><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href=/assets/external/font-awesome-4.7.0/css/font-awesome.css><link rel="stylesheet" href="/assets/css/style_dark.css"><link rel="stylesheet" href="/assets/css/style.css"> <script src="https://kit.fontawesome.com/6a97161b76.js" crossorigin="anonymous"></script> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5834956759419182" crossorigin="anonymous"></script><link rel="apple-touch-icon" sizes="180x180" href="/assets/logo.ico/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/logo.ico/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/logo.ico/favicon-16x16.png"><link rel="mask-icon" href="/assets/logo.ico/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#FFFFFF"></head><!-- Google tag (gtag.js) --> <script async src="https://www.googletagmanager.com/gtag/js?id=G-GBDTZMG942"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-GBDTZMG942'); </script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } }, tex2jax: { inlineMath: [ ['$','$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\[','\]'] ], processEscapes: true, } }); MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) { alert("Math Processing Error: "+message[1]); }); MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) { alert("Math Processing Error: "+message[1]); }); </script> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script><div id="load"> <img src="/assets/images/loading.gif" alt="loading"></div><script > const loading_page = document.getElementById("load"); window.onload = function(){ loading_page.style.display = 'none'; } </script></head><body><nav class="navbar is-black is-fixed-top" role="navigation" aria-label="main navigation" id="navbar"><div class="container"> <!-- logo or branding image on left side --><div class="navbar-brand"> <a class="navbar-item" href="http://localhost:4000/"> <strong>Welcome to my blog</strong> </a><div class="navbar-burger" data-target="navbar-menu"> <span></span> <span></span> <span></span></div></div><!-- children of navbar-menu must be navbar-start and/or navbar-end --><div class="navbar-menu has-background-black" id="navbar-menu"><div class="navbar-end"> <a class="navbar-item " href="http://localhost:4000/">HOME</a> <a class="navbar-item" href="http://localhost:4000/#about">ABOUT</a> <a class="navbar-item" href="http://localhost:4000/#contact">CONTACT</a> <a class="navbar-item " href="http://localhost:4000/cv">CV</a> <a class="navbar-item " href="http://localhost:4000/blog">POST</a><div class="navbar-item has-dropdown is-hoverable"> <a class="navbar-link"> CATEGORY </a><div class="navbar-dropdown has-background-black is-left"> <a href="http://localhost:4000/category/deep%20learning" class="navbar-item has-text-grey-light "> DEEP LEARNING </a> <a href="http://localhost:4000/category/development" class="navbar-item has-text-grey-light "> DEVELOPMENT </a> <a href="http://localhost:4000/category/github%20blog" class="navbar-item has-text-grey-light "> GITHUB BLOG </a> <a href="http://localhost:4000/category/paper%20review" class="navbar-item has-text-grey-light "> PAPER REVIEW </a></div></div><input id="darkmode_switch" class="mh_toogle" type="checkbox"> <label for="darkmode_switch" class="material-icons-sharp mh_toggle_btn"></label></div></div></div></nav><!-- Bulma Navbar JS --> <script> document.addEventListener('DOMContentLoaded', function () { /* Get all "navbar-burger" elements */ var $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0); /* Check if there are any navbar burgers */ if ($navbarBurgers.length > 0) { /* Add a click event on each of them */ $navbarBurgers.forEach(function ($el) { $el.addEventListener('click', function () { /* Get the target from the "data-target" attribute */ var target = $el.dataset.target; var $target = document.getElementById(target); /* Toggle the class on both the "navbar-burger" and the "navbar-menu" */ $el.classList.toggle('is-active'); $target.classList.toggle('is-active'); }); }); } }); </script> <script> function changeGiscusTheme () { function sendMessage(message) { const iframe = document.querySelector('iframe.giscus-frame'); if (!iframe) return; iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app'); } sendMessage({ setConfig: { theme: localStorage.theme } }); } /* 스타일 파일들 */ const defaultTheme = [...document.styleSheets].find(style => /(style.css)$/.test(style.href)); const darkTheme = [...document.styleSheets].find(style => /(style_dark.css)$/.test(style.href)); /* 스위치, 현재 테마 상태 불러오기 */ let mode = document.getElementById("darkmode_switch"); const current = localStorage.theme; /* 기존 상태에 따라 스위치 체크해주기 */ mode.checked = current === 'dark'; /* 체크된 거에 따라서 스타일 지정해주기 */ darkTheme.disabled = mode.checked !== true; defaultTheme.disabled = mode.checked === true; /* 토글 이벤트 리스너 */ mode.addEventListener('click', function(){ localStorage.theme = mode.checked ? 'dark' : 'light'; darkTheme.disabled = mode.checked !== true; defaultTheme.disabled = mode.checked === true; changeGiscusTheme(); }); </script> <span class="bar"></span><section class="hero is-fullheight has-text-centered" id="post"><div class="hero-body"><div class="container"> <a href="/blog/cs231n04" class="has-text-black" id="title"><h1 class="title has-text-centered is-2 has-text-weight-semibold ">cs231n 내용 요약 (4) - Backpropagation</h1></a><hr class="has-background-black"><div class="columns is-variable is-5"><div class="column is-6"><figure class="image is-16by9 has-shadow"> <img src="https://github.com/user-attachments/assets/cdb8f444-3819-448c-868e-03e4fabb4dcc" alt="" id="post-image"></figure></div><div class="subtitle column is-5 has-text-left-desktop has-text-left-fullhd has-text-left-tablet has-text-center-mobile"><p id="description" class="content is-small has-text-weight-medium is-uppercase">Lecture summary</p><p class="subtitle is-6 is-uppercase has-text-weight-normal has-text-black-ter">Published on <b>November 05, 2022</b> by <a href="https://github.com/6unoyunr" target="_blank"><b class="has-text-link"><u>JY</u></b> </a></p><p class="subtitle is-uppercase"> <i class="fa fa-tags"></i> <span class="tag is-link">AI</span> <span class="tag is-link">Deep learning</span> <span class="tag is-link">cs231n</span></p><p class="subtitle is-uppercase"><i class="fa fa-clock"></i> <b class="has-text-link"> 16 min </b>READ</p></div></div><div class="content has-text-justified-desktop has-text-justified-fullhd has-text-justified has-text-justified-tablet has-text-left-mobile"><p><h1 id="들어가며">들어가며…</h1><p>앞선 글에서 다루었던 내용들은 linear classification task에 대해 classifier로 사용될 수 있는 <strong>support vector machine</strong>(SVM)과 <strong>softmax</strong>에 대한 형태, 그리고 각각의 classifier의 <u>최적화 과정</u>에서 loss function으로 사용되는 <strong>hinge loss</strong>와 <strong>cross-entropy loss</strong>에 대해서 살펴볼 수 있었다. 또한 weight $W$와 bias $b$를 통해 parameterize되는 score function $f$ 및 loss function을 최적화할 수 있는 여러 방법들 중 <u>gradient descent</u>에 대해서 언급했었고, 모든 sample에 대한 analytic gradient를 구하는 연산 과정이 computationally cost했기 때문에 <u>stochastic gradient descent</u>(SGD) algorithm과 보다 noisy한 학습을 줄이고 빠른 최적화를 위한 방법인 mini-batch gradient descent에 대해서도 확인할 수 있었다. 지금부터 다룰 내용은 이전에 살펴본 단일 신경망(perceptron)을 포함한 다층 신경망 구조(Multilayer perceptron)에서 어떤 방식으로 parameter를 효율적으로 최적화할 수 있는지에 대한 방법론으로, 이 글에서 인공지능의 침체기와 그 발전 방향에 대한 역사 총체에 대해서 다룰 것이다.</p><hr /><h1 id="perceptron">Perceptron</h1><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/212449963-f797bdf8-6a43-46a6-993a-a57edb010647.png" width="700" /></p><p><u>인공 신경망</u>이라는 개념(Artificial neural network, ANN)은 1943년에 발표된 <a href="https://link.springer.com/article/10.1007/BF02478259">A logical calculus of the ideas immanent in nervous activity</a>에서 처음 제안되었다. 해당 논문을 publish한 McCulloch와 Pitts는 위와 같은 인간의 신경 구조를 복잡한 스위치들이 연결된(일종의 논리 함수) 네트워크로 표현할 수 있다고 설명하였다. 하지만 해당 연구에서는 perceptron을 실질적으로 활용할 생각은 못했고, 이보다 응용에 가까운 알고리즘을 제시한 것이 바로 현재의 인공지능 시대를 처음으로 열고자 했던 <a href="https://psycnet.apa.org/record/1959-09865-001">perceptron 논문</a> 이었고, 이는 1958년 Frank Rosenblatt에 의해 발표되었다. Resenblatt은 퍼셉트론이라는 선형 분류를 수행할 수 있는 feed forward neural network를 제안하였고, 이 구조는 우리가 흔히 알고 있는 input에 대해 weight를 곱하고, 여기에 activation function(활성화 함수)를 적용하여 그 값이 특정 threshold보다 크면 $1$, 작으면 $-1$을 출력하는 형태의 구조를 가지고 있었다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/212450295-57e6ec96-275f-4ef1-8e23-b8400958242a.png" width="700" /></p><p>현재 사용하고 있는 딥러닝도 형태만 살짝 다를 뿐 이러한 함수 구조를 여러 개의 node와 여러 개의 layer로 구성했다는 점에서 perceptron과의 근본적인 형태는 동일하다. Frank Rosenblatt의 perceptron은 현재의 딥러닝과 같이 당시에는 학계와 여러 언론으로부터 기대와 주목을 받았으며, <u>곧 세상을 인공지능이 대체할 수 있을 것</u>이라는 보도가 나기 시작했다. <br /> 그러나 이런 기대와 열기는 1969년 MIT의 Marvin Minsky와 Seymour Papert가 저자로 참여한 <a href="https://leon.bottou.org/publications/pdf/perceptrons-2017.pdf">Perceptrons</a>라는 책을 통해 한계를 수학적으로 증명당하면서 급격히 줄어들게 되었다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/212450524-bf186934-a43e-4d03-958f-4467ceaf6b01.png" width="700" /></p><p>Minsky와 Papert는 단순한 선형 분류를 할 수 있는 perceptron의 경우 <u>간단한 XOR 논리 연산을 추행할 수 없다</u>는 것을 지적하였고, 가장 간단한 논리 문제에서부터 제안된 방법론이 수행될 수 없다는 점은 인간의 일상생활에서 접할 수 있는 대부분의 문제를 해결할 수 없음을 의미하였다. Minsky는 이에 추가적으로 perceptron을 여러 층으로 구성한 multilayer perceptron(MLP)이 해당 논리 문제를 해결할 수 있을 것이라 제안했지만, 그와 동시에 MLP의 parameter를 학습할 수 있는 방법론을 제시하지 못하였다.</p><hr /><h1 id="multilayer-perceptron">Multilayer perceptron</h1><p>인공 신경망에 대한 한계점을 찾아내자, 연구자들의 관심은 금방 사그라들었지만 이에 굴하지 않고 꾸준히 연구를 계속하는 사람들도 있었다. 1986년 <a href="http://www.cs.toronto.edu/~fritz/absps/pdp2.pdf">Parallel Distributed Processing</a>라는 책을 통해 hidden layer를 가진 multi-layer perceptron과 backpropagation 알고리즘을 제시하였다. 기존의 perceptron은 단일 신경망 layer를 가지고 있었기 때문에 linear classification의 한계를 넘어설 수 없었지만, <u>multilayer perceptron</u>(MLP)는 hidden layer라는 추가 layer를 제안함으로써, XOR과 같은 문제에서 선형 분류선을 추가할 수 있는 가능성을 보여주었다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/212450702-29c12691-7823-47a3-9f32-9389888e5240.png" width="400" /></p><p>그러나 MLP의 경우 parameter의 수가 단일 perceptron에 비해 많아지면서 적절한 weight와 bias를 찾는 과정이 어려웠는데, 여기서 backpropation 알고리즘이 제안되면서 이 문제를 해결할 수 있었다. Backpropagation algorithm이란 input을 다층 신경망에 정방향(feed-forward) 방향으로 통과시킨 후 output값(에측값)을 토대로 원하는 기준(ground truth)와 비교함으로써, 해당 차이(error)를 역방향(backward)으로 돌려주면서 <u>parameter를 update</u>하게 된다.</p><hr /><h1 id="backpropagation">Backpropagation</h1><p>사실 concept만 이런 식으로 정의하게 되면 이해가 쉽지 않기 때문에 다음과 같은 예시를 들어보도록 하겠다. 이전에 다루었던 단일 신경망(perceptron)을 활용한 선형 분류기의 경우 score function $f$을 구성하는 요소가 weight 및 bias 였고, 이를 단순한 trick을 사용하여 단일 layer의 parameter를 weight로만 정의할 수 있었다. 이를 식으로 표현하게 되면 score function $f$와 loss function $\rho$에 대하여,</p><p>[ \begin{aligned} \hat{y} =&amp; f(W;~X) = X \cdot W \newline \delta =&amp; \rho(\hat{y},~y) \end{aligned} <br /> ]</p><p>score function $f$를 통해 예측한 prediction $\hat{y}$과 ground truth $y$를 loss metric $\rho$를 통해 비교한 error 값인 $\delta$를 정의할 수 있다. Error가 의미하는 바는 곧 output이 <u>이동해야할 방향</u>(direction)와 같다. 다르게 말하자면 input $W,~x$에 대한 prediction $\hat{y}$의 변화량을 제시했기 때문에, 기준점에 대한 input의 변화량은 미분을 통해 구할 수 있다. 길게 돌고 돌아서 설명하긴 했지만 이전에 설명했던 gradient descent 방식을 풀어서 설명한 것이다. Parameter인 <u>$W$의 변화량에 대한 $\delta$의 변화</u>는 다음과 같다.</p><p>[ \frac{\partial \delta}{\partial W} <br /> ]</p><p>여기서 만약 $\delta$ 값을 구할 수 있다면, 이에 따라 $W$의 변화량도 계산할 수 있다. 물론 여기서 구한 변화량은 hyperplane에 대한(tangential plane) direction이 되기 때문에 실제 loss function의 global minima를 찾을 수는 없다. 이 역시 step size를 기반으로 조금씩 내려가는 형태의 <u>gradient descent</u> 알고리즘을 적용해야한다.</p><p>[ \delta_W = \delta \times \frac{\partial W}{\partial \delta} = \delta \times \frac{\partial \hat{y}}{\partial \delta} \times \frac{\partial W}{\partial \hat{y}} ]</p><p>방금은 layer가 하나인 경우에 대해서만 설명하였고, 만약 이러한 layer가 여러 층 있다고 생각해보자. 식에서 $\sigma$는 <u>activation function</u>으로 생각해주면 된다.</p><p>[ \begin{aligned} \hat{y} = f(W_1,~W_2,~\cdots,~W_n;~X) =&amp; \sigma( \cdots \sigma(\sigma(X \cdot W_1) \cdot W_2) \cdots W_n) \newline \delta =&amp; \rho(\hat{y},~y) \end{aligned} <br /> ]</p><p>수식을 단순하게 하기 위해 $y_k$는 $k$번째 레이어 이후의 결과값이라고 생각해보자. 따라서 위의 수식에서 $\hat{y} = y_n$이다. 앞서 단일 perceptron의 경우와 동일하게 이번에도 output의 변화량에 대한 input의 변화량을 나타낼 수 있다.</p><p>[ \delta_{W_n} = \delta \times \frac{\partial \sigma}{\partial \delta} \times \frac{\partial W_n}{\partial \sigma} = \delta \times \frac{\partial y_n}{\partial \delta} \times \frac{\partial \sigma}{\partial y_n} \times \frac{\partial W_n}{\partial \sigma} ]</p><p>다만 이번에는 output $\hat{y}$가 activation function $\sigma$에 대한 추가 합성 함수로 구성되기 때문에 위와 같은 <u>chain rule</u>을 따르게 된다. 마찬가지로,</p><p>[ \delta_{W_{n-1}} = \delta \times \frac{\partial \sigma}{\partial \delta} \times \frac{\partial y_{n-1}}{\partial \sigma} \times \frac{\partial W_{n-1}}{\partial y_{n-1}} ]</p><p>위와 같이 forward 과정에서 이미 연산된 결과 $y_k$에 대해 local derivatives를 계속해서 계산된 미분값에 곱해가게 되고, 이를 backpropagation이라고 한다. 위는 multilayer perceptron에 대한 예시였고, 다음과 같은 간단한 논리 회로에 대해 예시를 보게 되면</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/212582088-59a9e8b1-aaab-4be0-9016-b13966f4aa50.png" width="400" /></p><p>초록색으로 표시된 값들이 실제 input($x,~y,~z$ 그리고 논리 연산에 의한 값)이고, 빨간색으로 표시된 값들이 미분값에 해당된다. 위와 같이 input에 대해 어떠한 결과가 도출되는 복잡한 신경망 회로를 구성한 것이 multilayer perceptron이다. 이를 학습시키기 위해 backpropagation을 진행하는 과정을 <u>직관적인 그림</u>으로 표현한 것이 위의 그림이다. 첫번째 빨간색 미분값은 앞서 보았던 metric에 의한 오차 그대로를 미분한 것과 같다. 논리 회로를 하나의 함수 $f$라고 생각한다면 이를 $f$로 미분한 결과는 그대로 $1$이 되기 때문이다. 그 다음으로 볼 수 있는 두번째 빨간색 미분값($q$라고 적혀있는 부분에 해당)은 $-4$이다. 왜냐하면 $f = qz$를 $q$로 편미분한 것은 $z$값이기 때문이다. 세번째 빨간색 미분값($x$라고 적혀있는 부분에 해당)은 $-4$이다. 왜냐하면 $f = qz = (x+y)z$를 $x$로 편미분한 것은 $z$값이기 때문이다(by chain rule). 네번째 빨간색 미분값($y$라고 적혀있는 부분에 해당)은 $-4$이다. 왜냐하면 $f = (x+y)z$를 $y$로 편미분한 것은 $z$값이기 때문이다(by chain rule). 그리고 마지막 빨간색 미분값($z$라고 적혀있는 부분에 해당)은 $3$이다. 왜냐하면 $f$를 $z$로 편미분한 것은 $x+y$값이기 때문이다. 이 논리 회로의 연산 과정은 간단하고, 크게 어렵지 않지만 해당 예시에서 얻어갈 수 있는 insight는 다음과 같다.</p><ul><li>Forward process 과정에서 계산된 output이 backward process 과정에서의 각 input에 대한 gradient 연산에 사용된다.</li><li>가장 말단(신경망 전체 함수 $f$의 끝부분)에서 계산된 gradient를 기준으로 이전 과정의 gradient가 chain rule에 의해 곱해지는 구조가 된다.</li></ul><hr /><h1 id="backpropagation의-해석">Backpropagation의 해석</h1><p>Backpropagation은 <u>local process</u>(지역적 연산 결과)이다. 회로 다이어그램에서의 각 gate는 input을 받아 두 가지 계산 결과를 가진다. 첫번째는 말 그대로 gate의 논리에 따른 연산 결과(위의 그림 예시에서 볼 수 있었던 초록색 값), 그리고 두번째는 input에 대한 output의 local gradient(위의 그림 예시에서 볼 수 있었던 빨간색 값)를 계산한 값이다. 실제로 gate가 속해있는 전체 회로가 어떤 구조로 구성되어있어도 이와는 상관없이 <u>각 gate에서 수행되는 논리 계산</u>과 <u>gradient 계산</u>은 완전히 독립적으로 생각할 수 있다. 그렇기에 forward pass가 한번 끝나게 되면, backpropagation이 진행되는 동안에 전체 회로의 output value를 기준으로 신경망을 구성하는 모든 parameter에 대해서 gradient를 계산할 수 있는 것이다. 이를 실질적으로 수행할 수 있게 만드는 수학적 메커니즘인 chain rule로 하여금 gate의 <u>모든 input에 대해 gradient를 곱하는</u> 형태로 계산이 진행되어야하는 것이다. 여기서 gradient의 곱은 반대로 가는 경로(backward process)에 놓이는 모든 output에 대해서 생각해주면 된다. 즉, chain rule에 따른 multiplication은 곧 복잡한 신경망 회로 내에서 서로 무관하게 놓인 perceptron들을 <u>유기적으로 학습</u>할 수 있는 방법론이 된 것이다. 앞의 예시를 다시 가져와서 생각해보면,</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/212582088-59a9e8b1-aaab-4be0-9016-b13966f4aa50.png" width="400" /></p><p>덧셈 연산을 수행하는 gate는 input으로 $-2$, $5$를 받고 output인 $3$을 내보냈다. Gate는 단순히 input에 대해서 덧셈을 수행하기 때문에, 모든 input에 대한 gradient는 $+1$이다. 덧셈 연산을 수행하는 gate를 포함한 전체 논리회로는 최종 결과인 $-12$를 출력한다. Backward pass(backpropagation) 과정에서 chain rule이 적용되고, backpropagation 연산 결과, 덧셈 gate는 해당 output에 대한 gradient로 $-4$를 가지게 된다. 여기서 만약 회로가 만약 <u>'output으로 더 큰 값을 뽑아내길 원한다'</u>고 생각해보자. 회로에서 덧셈 gate의 gradient가 마이너스값($-4$)이었으니, 실제로 덧셈 gate의 output으로는 <u>더 작은 값을 원하겠거니</u> 생각할 수 있다. 빨간색으로 계산된 gradient 결과는 결국 output에 대한 각 gate output의 변화량 및 방향을 표현한 것이기 때문이다. Backpropation을 진행하는 과정에서, 덧셈 gate는 자기가 받는 모든 input(그림에서는 $x$, $y$)에 대한 local gradient에 덧셈 gate의 output $q$에 대한 gradient를 모두 곱하게 된다. 따라서, input $x$에 대해서나 $y$에 대해서 모두 $1 \times (-4) = -4$가 되는 것이다. 이를 토대로 우리가 input과 회로 전체에 대해 이해할 수 있는 바는 $x$, $y$가 모두 감소하게 되면 덧셈 gate의 output도 감소하게 되고, gate의 output은 증가하게 된다는 것이다. 이를 요약하자면 회로의 output으로 하여금 <u>gate에 적용되는 gradient</u>에 해당 gate의 input 변수들의 local gradient를 곱하게 되면 각 input들의 적용되는 gradient를 계산할 수 있고, 이를 통해 <u>각 input이 어떤 방향으로 얼만큼 변화해야</u> <strong>원하는 output을 얻을 수 있는지</strong>에 대한 정보를 알아낼 수 있다. 회로 안의 모든 gate는 backpropagation이라는 과정을 통해 서로 소통할 수 있게 되고, 소통 수단은 chain rule을 기반으로 계산된 값이 될 것이다.</p><hr /><h1 id="example-of-two-dimensional-neuron">Example of two dimensional neuron</h1><p>[ f(w,~x) = \frac{1}{1+e^{-(w_0x_0 + w_1x_1 + w_2)}} <br /> ]</p><p>위의 식은 입력 차원이 $2$인 단일 신경망에 대해서 sigmoid activation function을 적용하는 간단한 회로이다. 위의 식에서 사용되는 각 논리 회로에 대한 미분은 다음과 같다.</p><p>[ \begin{aligned} f(x) =&amp; \frac{1}{x} \rightarrow \frac{df}{dx} = -\frac{1}{x^2} \newline f(x) =&amp; x + c \rightarrow \frac{df}{dx} = 1 \newline f(x) =&amp; e^x \rightarrow \frac{df}{dx} = e^x \newline f(x) =&amp; ax \rightarrow \frac{df}{dx} = a \end{aligned} <br /> ]</p><p>식을 기반으로 회로를 구성하면 다음과 같은 그림이 된다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/212587574-66d72e68-6c54-49a4-84f5-9cb9ebcff619.png" width="900" /></p><p>그림을 보면 각 연산 순서에 맞게 value(초록색)와 gradient(빨간색)를 계산해놓은 것을 알 수 있다. 앞서 예제에서 했던 것과 같이 backpropagation을 진행하면 다음과 같다. 가장 output인 $1.00$을 기준으로 시작해보자. $\frac{1}{x}$ gate에 대한 local gradient 식은 $\frac{df}{dx} = -\frac{1}{x^2}$가 된다. 식에서 $x$에 유일한 input인 $1.37$을 대입하고, 역방향을 기준으로 gate의 gradient를 모두 곱하면 $1 \times (-1/(1.37)^2) = -0.53$이다. 그 다음에 있는 1을 더하는 operation은 gradient에 영향을 주지 않기 때문에(input에 상관없이 local gradient가 1이기 때문에) $-0.53$이 그대로 전달된다. <br /> 그 다음으로 exponential operation에 대한 local gradient($\frac{df}{dx} = e^x$)는 input에 대한 output과 local gradient가 서로 같은 값을 가지기 때문에, 앞서 연산된 gradient에 output을 곱하게 되면 $-0.53 \times 0.37 = -0.20$이 된다. $-1$을 곱하는 연산은 gradient 부호를 바꾸는 연산이 되므로 전달되는 값은 $(-0.20) \times (-1) = 0.20$이 된다. <br /> 이후로는 input이 두 갈래로 나뉘게 되는데, 우선 $w2$와 이어진 부분을 보게 되면 덧셈 연산으로 구성되기 때문에 gradient가 변수에 대해서 $1$이 고정값으로 쓰인다. 따라서 $0.20$이 그대로 유지된다. 위쪽으로도 또다른 덧셈 연산이 이어지고, 여기서도 동일하게 $0.20$이 유지되는 것을 알 수 있다. 다시 위쪽 덧셈 연산 gate를 기준으로 두 갈래로 나뉘게 되는데, 여기서도 마찬가지로 덧셈 연산이기 때문에 $0.20$의 gradient가 유지된다. <br /> 남은 부분은 곱셈 연산 gate인데, gate로 전달된 gradient가 $0.20$이기 때문에 여기서 서로 다른 input을 곱한 것이 해당 input에 대한 gradient가 된다. 예를 들어 $f(x,~y) = xy$인 gate가 있다면, 각 input에 대한 local gradient는 $\frac{\partial f}{\partial x} = y,~\frac{\partial f}{\partial y} = x$가 되는 것이다. 이를 토대로 계산하게 되면 $w0$에 대한 gradient는 $0.20 \times x0 = -0.20$, $x0$에 대한 gradient는 $0.20 \times w0 \simeq 0.39$(여기서 연산이 살짝 안 맞는데, 이 부분은 소숫점 아래 두번째 자리까지 반올림하면서 생긴 오차인 듯)이 된다. $w1,~x1$에 대한 gradient도 같은 방법을 통해 계산하게 되면 각각 $-0.39,~-0.59$가 되는 것을 쉽게 알 수 있다.</p><hr /><h1 id="sigmoid-function-gradient">Sigmoid function gradient</h1><p>위에서 사용된 회로는 sigmoid function을 여러 기본 논리 회로를 통해 표현한 형태가 된다. 그러나 굳이 이렇게 세세히 분리할 필요 없이 sigmoid function의 analytic한 도함수를 구할 수 있다.</p><p>[ \begin{aligned} \sigma (x) =&amp; \frac{1}{1+e^{-x}} \newline \frac{d \sigma(x)}{dx} =&amp; \frac{e^{-x}}{(1+e^{-x})^2} \end{aligned} <br /> ]</p><p>Sigmoid function의 도함수는 다음과 같이 표현할 수 있다.</p><p>[ \frac{d \sigma(x)}{dx} = \left( \frac{1+e^{-x}-1}{1+e^{-x}} \right)\left( \frac{1}{1+e^{-x}} \right) = (1-\sigma(x))\sigma(x)<br /> ]</p><p>그렇다면 위에서 계산된 결과를 토대로 보게 되면, $w0x0 + w1x1 + w2$가 곧 sigmoid function의 input인 $x$가 되기 때문에 $\sigma(x) = 0.73$, $\sigma (x)(1-\sigma (x)) = 0.73 \times (1-0.73) = 0.1971$임을 바로 구할 수 있다.</p><hr /><h1 id="결론">결론</h1><p>기존 linear classification만 가능했던 퍼셉트론의 한계를 극복하기 위해 다층 신경망 구조를 역사와 함께 간단하게 소개했고, 그러한 다층 신경망을 학습시키기 위한 방법으로 제시된 backpropagation이란 개념을 알아볼 수 있었다. Backpropagation은 각 레이어마다 local gradient 계산을 통해 모든 신경망 구조의 요소들을 유기적으로 엮어주는 역할을 했으며, perceptron이 해결하지 못한 실생활의 task에 적용될 수 있는 딥러닝의 발전이 시작된 지점이었다.</p><hr /><h1 id="appendix">Appendix</h1><h5 id="question--draw-a-model-diagram-of-following-equation-and-calculate-gradient-with-python-simulation">Question : Draw a model diagram of following equation and calculate gradient with python simulation.</h5><p>[ f(x,~y) = \frac{x+\sigma (y)}{\sigma (x) + (x+y)^2} <br /> ]</p><h5 id="answer">Answer</h5><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/212597740-e67d424b-86a6-40aa-90a5-2e5ec6036749.png" width="700" /></p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># example values
</span><span class="n">y</span> <span class="o">=</span> <span class="o">-</span><span class="mi">4</span>

<span class="c1"># forward pass
</span><span class="n">sigy</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">y</span><span class="p">))</span> <span class="c1"># sigmoid in numerator   #(1)
</span><span class="n">num</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">sigy</span> <span class="c1"># numerator                               #(2)
</span><span class="n">sigx</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span> <span class="c1"># sigmoid in denominator #(3)
</span><span class="n">xpy</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>                                              <span class="c1">#(4)
</span><span class="n">xpysqr</span> <span class="o">=</span> <span class="n">xpy</span><span class="o">**</span><span class="mi">2</span>                                          <span class="c1">#(5)
</span><span class="n">den</span> <span class="o">=</span> <span class="n">sigx</span> <span class="o">+</span> <span class="n">xpysqr</span> <span class="c1"># denominator                        #(6)
</span><span class="n">invden</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">den</span>                                       <span class="c1">#(7)
</span><span class="n">f</span> <span class="o">=</span> <span class="n">num</span> <span class="o">*</span> <span class="n">invden</span> <span class="c1"># done!                                 #(8)
</span>
<span class="c1"># backprop f = num * invden
</span><span class="n">dnum</span> <span class="o">=</span> <span class="n">invden</span> <span class="c1"># gradient on numerator                             #(8)
</span><span class="n">dinvden</span> <span class="o">=</span> <span class="n">num</span>                                                     <span class="c1">#(8)
# backprop invden = 1.0 / den 
</span><span class="n">dden</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">den</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="n">dinvden</span>                                <span class="c1">#(7)
# backprop den = sigx + xpysqr
</span><span class="n">dsigx</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dden</span>                                                <span class="c1">#(6)
</span><span class="n">dxpysqr</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dden</span>                                              <span class="c1">#(6)
# backprop xpysqr = xpy**2
</span><span class="n">dxpy</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">xpy</span><span class="p">)</span> <span class="o">*</span> <span class="n">dxpysqr</span>                                        <span class="c1">#(5)
# backprop xpy = x + y
</span><span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dxpy</span>                                                   <span class="c1">#(4)
</span><span class="n">dy</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dxpy</span>                                                   <span class="c1">#(4)
# backprop sigx = 1.0 / (1 + math.exp(-x))
</span><span class="n">dx</span> <span class="o">+=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigx</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigx</span><span class="p">)</span> <span class="o">*</span> <span class="n">dsigx</span>                                 <span class="c1">#(3)
# backprop num = x + sigy
</span><span class="n">dx</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dnum</span>                                                  <span class="c1">#(2)
</span><span class="n">dsigy</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dnum</span>                                                <span class="c1">#(2)
# backprop sigy = 1.0 / (1 + math.exp(-y))
</span><span class="n">dy</span> <span class="o">+=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigy</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigy</span><span class="p">)</span> <span class="o">*</span> <span class="n">dsigy</span>                                 <span class="c1">#(1)
</span></code></pre></div></div><h5 id="answer-solution">Answer solution</h5><p>코드에 맞게끔 다이어그램에서의 value와 gradient를 매칭시키면 다음과 같다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/212598822-4e6e5958-2a9f-48dc-b96b-2b9bc5ff9f85.png" width="500" /> <img src="https://user-images.githubusercontent.com/79881119/212598817-aa15d8c5-02d8-474d-aff1-e822bb2973fd.png" width="500" /></p><p>빨간색으로 표시된 부분이 forward process에서 계산된 value, 초록색으로 표시된 부분이 backward 연산 시 계산된 gradient를 변수명에 맞게 위치시킨 것이다. 가장 먼저, $f(x,~y)$를 기준으로 곱셈 연산 gate가 있기 때문에 앞선 예제에서와 같이 input을 서로 교차해서 곱해주면된다. Output에 대한 gradient는 $1$이기 때문에, $1$에 각각의 input을 곱해주면 된다. 따라서 코드는 다음과 같다.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># backprop f = num * invden
</span><span class="n">dnum</span> <span class="o">=</span> <span class="n">invden</span> <span class="c1"># gradient on numerator                             #(8)
</span><span class="n">dinvden</span> <span class="o">=</span> <span class="n">num</span>                                                     <span class="c1">#(8)
</span></code></pre></div></div><p>다음으로는 $1/x$ 연산에 대한 gradient를 곱해주기 위해 input인 <code class="language-plaintext highlighter-rouge">den</code>에 대한 $-1/x^2$을 곱해준다. 코드는 다음과 같다.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># backprop invden = 1.0 / den 
</span><span class="n">dden</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">den</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="n">dinvden</span>                                <span class="c1">#(7)
</span></code></pre></div></div><p>그리고 <code class="language-plaintext highlighter-rouge">xpysqr</code>과 <code class="language-plaintext highlighter-rouge">sigx</code>가 더해지게 되므로, <code class="language-plaintext highlighter-rouge">dsigx</code>와 <code class="language-plaintext highlighter-rouge">dxpysqr</code>은 각각 <code class="language-plaintext highlighter-rouge">dden</code>의 gradient가 그대로 유지된다.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># backprop den = sigx + xpysqr
</span><span class="n">dsigx</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dden</span>                                                <span class="c1">#(6)
</span><span class="n">dxpysqr</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dden</span>                                              <span class="c1">#(6)
</span></code></pre></div></div><p>제곱에 대한 gradient는 쉽게 구할 수 있으므로 <code class="language-plaintext highlighter-rouge">dxpy</code>는 넘어가도록 하겠다.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># backprop xpysqr = xpy**2
</span><span class="n">dxpy</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">xpy</span><span class="p">)</span> <span class="o">*</span> <span class="n">dxpysqr</span>                                        <span class="c1">#(5)
</span></code></pre></div></div><p>마찬가지로 <code class="language-plaintext highlighter-rouge">dxpy</code>의 gradient는 덧셈 게이트의 input인 <code class="language-plaintext highlighter-rouge">x</code>와 <code class="language-plaintext highlighter-rouge">y</code>에 대해 그대로 유지된다. 따라서 <code class="language-plaintext highlighter-rouge">dx</code>와 <code class="language-plaintext highlighter-rouge">dy</code>는 다음과 같다.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># backprop xpy = x + y
</span><span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dxpy</span>                                                   <span class="c1">#(4)
</span><span class="n">dy</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dxpy</span>                                                   <span class="c1">#(4)
</span></code></pre></div></div><p>앞선 예제에서 $\sigma$ 함수의 gradient를 표현하는 방법에 대해서 알아보았다. 해당 공식을 그대로 사용하게 되면 output인 <code class="language-plaintext highlighter-rouge">sigx</code>에 대해서</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># backprop sigx = 1.0 / (1 + math.exp(-x))
</span><span class="n">dx</span> <span class="o">+=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigx</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigx</span><span class="p">)</span> <span class="o">*</span> <span class="n">dsigx</span>                                 <span class="c1">#(3)
</span></code></pre></div></div><p>위와 같으며, 기존에 이미 연산된 <code class="language-plaintext highlighter-rouge">dx</code>가 있기 때문에 여기에 추가로 더해주게 된다. <code class="language-plaintext highlighter-rouge">dnum = x + sigy</code>에 대해 덧셈 gate는 gradient가 유지되므로 다음과 같이 계산할 수 있다.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># backprop num = x + sigy
</span><span class="n">dx</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dnum</span>                                                  <span class="c1">#(2)
</span><span class="n">dsigy</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dnum</span>                                                <span class="c1">#(2)
</span></code></pre></div></div><p>여기에 마지막으로 $\sigma$ 함수의 gradient를 계산해주면 마무리된다.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># backprop sigy = 1.0 / (1 + math.exp(-y))
</span><span class="n">dy</span> <span class="o">+=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigy</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigy</span><span class="p">)</span> <span class="o">*</span> <span class="n">dsigy</span>                                 <span class="c1">#(1)
</span></code></pre></div></div></p></div></div></div></section><div class="contain_cats" align="center"><div class="contain_category" align="center"><div class="anothercat" align="center"><body><div class="waviy"> <span style="--i:1">A</span> <span style="--i:1">n</span> <span style="--i:1">o</span> <span style="--i:1">t</span> <span style="--i:1">h</span> <span style="--i:1">e</span> <span style="--i:1">r</span> <span style="--i:2"> </span> <span style="--i:2"> </span> <span style="--i:2"> </span> <span style="--i:3">p</span> <span style="--i:3">o</span> <span style="--i:3">s</span> <span style="--i:3">t</span> <span style="--i:4"> </span> <span style="--i:4"> </span> <span style="--i:4"> </span> <span style="--i:5">i</span> <span style="--i:5">n</span> <span style="--i:6"> </span> <span style="--i:6"> </span> <span style="--i:6"> </span> <span style="--i:7">c</span> <span style="--i:7">a</span> <span style="--i:7">t</span> <span style="--i:7">e</span> <span style="--i:7">g</span> <span style="--i:7">o</span> <span style="--i:7">r</span> <span style="--i:7">y</span></div></body></div><div class="adjacent"><div class="prev_btn"> <a id="prev" class="button" href="/blog/cs231n03"><p id="prev_title"> ❮❮ cs231n 내용 요약 (3) - Optimization(최적화)</p></a></div><div class="next_btn"> <a id="next" class="button" href="/blog/cs231n05"><p id="next_title"> ❯❯ cs231n 내용 요약 (5) - Neural Network</p></a></div></div></div></div><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script> <script> const title1 = $("#prev_title").text(); const title2 = $('#next_title').text(); var speed = 100; var dots = '⋯⋯'; var titlelength = function () { setInterval(function () { var ww = $(window).width(); if(ww < 400){ offset = 10; if(title1.length > offset){ part = title1.substr(0, offset); $("#prev_title").text(part + dots); } if(title2.length > offset){ part = title2.substr(0, offset); $("#next_title").text(part + dots) } } else if(ww < 600){ offset = 20; if(title1.length > offset){ part = title1.substr(0, offset); $("#prev_title").text(part + dots); } if(title2.length > offset){ part = title2.substr(0, offset); $("#next_title").text(part + dots) } } else{ $("#prev_title").text(title1); $("#next_title").text(title2); } }, speed); }; $(document).ready(function () { titlelength(); }); </script><div class="utterance-light" id="comment_light"> <script src="https://utteranc.es/client.js" repo="6unoyunr/comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div><div class="utterance-dark" id="comment_dark"> <script src="https://utteranc.es/client.js" repo="6unoyunr/comments" issue-term="pathname" theme="github-dark" crossorigin="anonymous" async> </script></div><footer id="footer"> <!--Footer Button--><div class="container has-text-centered has-background-grey-darker" id="backtotop"> <a class="has-text-white" onclick="window.scroll(0,0)">BACK TO TOP</a></div><!--Footer Main Section--><div class="has-background-grey-darker"><div class="container columns"> <!--Name Section--><div class="column has-text-left-desktop has-text-centered-mobile"> <a href="http://localhost:4000/#about"><div class="columns"><div class="column is-one-fifth-desktop is-one-fifth-fullhd is-one-quarter-tablet"><figure class="image is-64x64"> <img class="is-rounded" src="https://avatars.githubusercontent.com/u/201962047?v=4"></figure></div><div class="column is-marginless"><h5 class="has-text-grey-lighter">JY</h5><div class="content has-text-grey"><p>I am an AI researcher with a strong interest in machine learning and dee...</p></div></div></div></a></div><!--Link Section--><div class="column has-text-white"><h3>More Links</h3><li> <a href="http://localhost:4000/category/development">DEVELOPMENT</a></li><li> <a href="http://localhost:4000/category/github%20blog">GITHUB BLOG</a></li><li> <a href="http://localhost:4000/category/paper%20review">PAPER REVIEW</a></li></div><!--Blog-post Section--><div class="column has-text-white"><h3>Recent Posts</h3><li> <a href="http://localhost:4000/blog/reasoning">추론 모델은 정말로 뛰어난가?? 오픈소스 엑사원 딥(EXAONE-Deep), QWQ, 딥시크(Deepseek-R1) 비교 실험해보기</a></li><li> <a href="http://localhost:4000/blog/deepseekr1">딥시크(Deepseek)-R1에 대한 고찰. Thinking about Deepseek-R1 with Reinforcement Learning(RL).</a></li><li> <a href="http://localhost:4000/blog/mamba">Mamba modeling의 기초 (3) - Linear-Time Sequence Modeling with Selective State Spaces (Mamba)에 대하여</a></li></div></div></div><div class="has-background-black has-text-centered has-text-white" id="credits"></div></footer></body></html><script> $(window).scroll(function() { var scrollY = ($(window).scrollTop() / ($(document).height() - $(window).height()) * 100).toFixed(3); $(".bar").css({"width" : scrollY + "%"}); }); </script>

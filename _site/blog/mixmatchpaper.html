<!DOCTYPE html><html><head><head> <!-- Include Meta Tags Here --><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta http-equiv="X-UA-Compatible" content="ie=edge"><meta name="viewport" content="width=device-width, height=device-height, initial-scale=1 user-scalable=no, shrink-to-fit=no"><meta content='#000000' name='theme-color'/><meta name="keywords" content="AI, Developer, Research engineer"><title>Welcome to my blog | MixMatch-A holistic approach to semi-supervised learning에 대하여</title><!-- Open Graph general (Facebook, Pinterest & Google+) --><meta name="og:title" content="Welcome to my blog | MixMatch-A holistic approach to semi-supervised learning에 대하여"><meta name="og:description" content="paper review"><meta name="og:image" content="https://user-images.githubusercontent.com/79881119/235352836-99c2a2ef-1197-4bb2-a730-1e48fcf60ded.jpg"><meta name="og:image:alt" content="Welcome to my blog | MixMatch-A holistic approach to semi-supervised learning에 대하여"><meta name="og:url" content="http://localhost:4000/blog/mixmatchpaper"><meta name="article:author" content="https://www.facebook.com/"><meta name="og:site_name" content="Welcome to my blog | MixMatch-A holistic approach to semi-supervised learning에 대하여"><meta name="og:type" content="website"> <!-- Twitter --><meta property="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Welcome to my blog | MixMatch-A holistic approach to semi-supervised learning에 대하여"><meta name="twitter:description" content="paper review"><meta name="twitter:site" content="@"><meta name="twitter:creator" content="@"><meta name="twitter:image:src" content="https://user-images.githubusercontent.com/79881119/235352836-99c2a2ef-1197-4bb2-a730-1e48fcf60ded.jpg"> <!-- Search Engine --><meta name="description" content="paper review"><meta name="image" content="https://user-images.githubusercontent.com/79881119/235352836-99c2a2ef-1197-4bb2-a730-1e48fcf60ded.jpg"> <!-- Schema.org for Google --><meta itemprop="name" content="Welcome to my blog | MixMatch-A holistic approach to semi-supervised learning에 대하여"><meta name="author" content="JY"/><meta itemprop="description" content="paper review"><meta itemprop="image" content="https://user-images.githubusercontent.com/79881119/235352836-99c2a2ef-1197-4bb2-a730-1e48fcf60ded.jpg"> <!-- Global site tag (gtag.js) - Google Analytics --> <script async src="https://www.googletagmanager.com/gtag/js?id=G-KFNS88G1GM"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'G-KFNS88G1GM'); </script><title>Welcome to my blog</title><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href=/assets/external/font-awesome-4.7.0/css/font-awesome.css><link rel="stylesheet" href="/assets/css/style_dark.css"><link rel="stylesheet" href="/assets/css/style.css"> <script src="https://kit.fontawesome.com/6a97161b76.js" crossorigin="anonymous"></script> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5834956759419182" crossorigin="anonymous"></script><link rel="apple-touch-icon" sizes="180x180" href="/assets/logo.ico/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/logo.ico/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/logo.ico/favicon-16x16.png"><link rel="mask-icon" href="/assets/logo.ico/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#FFFFFF"></head><script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } }, tex2jax: { inlineMath: [ ['$','$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\[','\]'] ], processEscapes: true, } }); MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) { alert("Math Processing Error: "+message[1]); }); MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) { alert("Math Processing Error: "+message[1]); }); </script> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script><div id="load"> <img src="/assets/images/loading.gif" alt="loading"></div><script > const loading_page = document.getElementById("load"); window.onload = function(){ loading_page.style.display = 'none'; } </script></head><body><nav class="navbar is-black is-fixed-top" role="navigation" aria-label="main navigation" id="navbar"><div class="container"> <!-- logo or branding image on left side --><div class="navbar-brand"> <a class="navbar-item" href="http://localhost:4000/"> <strong>Welcome to my blog</strong> </a><div class="navbar-burger" data-target="navbar-menu"> <span></span> <span></span> <span></span></div></div><!-- children of navbar-menu must be navbar-start and/or navbar-end --><div class="navbar-menu has-background-black" id="navbar-menu"><div class="navbar-end"> <a class="navbar-item " href="http://localhost:4000/">HOME</a> <a class="navbar-item" href="http://localhost:4000/#about">ABOUT</a> <a class="navbar-item" href="http://localhost:4000/#contact">CONTACT</a> <a class="navbar-item " href="http://localhost:4000/cv">CV</a> <a class="navbar-item " href="http://localhost:4000/blog">POST</a><div class="navbar-item has-dropdown is-hoverable"> <a class="navbar-link"> CATEGORY </a><div class="navbar-dropdown has-background-black is-left"> <a href="http://localhost:4000/category/deep%20learning" class="navbar-item has-text-grey-light "> DEEP LEARNING </a> <a href="http://localhost:4000/category/development" class="navbar-item has-text-grey-light "> DEVELOPMENT </a> <a href="http://localhost:4000/category/github%20blog" class="navbar-item has-text-grey-light "> GITHUB BLOG </a> <a href="http://localhost:4000/category/paper%20review" class="navbar-item has-text-grey-light "> PAPER REVIEW </a> <!--<hr class="navbar-divider"> <a class="navbar-item"> Report an issue </a> --></div></div><input id="darkmode_switch" class="mh_toogle" type="checkbox"> <label for="darkmode_switch" class="material-icons-sharp mh_toggle_btn"></label></div></div></div></nav><!-- Bulma Navbar JS --> <script> document.addEventListener('DOMContentLoaded', function () { /* Get all "navbar-burger" elements */ var $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0); /* Check if there are any navbar burgers */ if ($navbarBurgers.length > 0) { /* Add a click event on each of them */ $navbarBurgers.forEach(function ($el) { $el.addEventListener('click', function () { /* Get the target from the "data-target" attribute */ var target = $el.dataset.target; var $target = document.getElementById(target); /* Toggle the class on both the "navbar-burger" and the "navbar-menu" */ $el.classList.toggle('is-active'); $target.classList.toggle('is-active'); }); }); } }); </script> <script> function changeGiscusTheme () { const gitcus_theme = localStorage.theme === 'dark' ? 'dark' : 'light'; function sendMessage(message) { const iframe = document.querySelector('iframe.giscus-frame'); if (!iframe) return; iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app'); } sendMessage({ setConfig: { theme: gitcus_theme } }); } /* 스타일 파일들 */ const defaultTheme = [...document.styleSheets].find(style => /(style.css)$/.test(style.href)); const darkTheme = [...document.styleSheets].find(style => /(style_dark.css)$/.test(style.href)); /* 스위치, 현재 테마 상태 불러오기 */ let mode = document.getElementById("darkmode_switch"); const current = localStorage.theme; /* 기존 상태에 따라 스위치 체크해주기 */ mode.checked = current === 'dark'; changeGiscusTheme(); /* 체크된 거에 따라서 스타일 지정해주기 */ darkTheme.disabled = mode.checked !== true; defaultTheme.disabled = mode.checked === true; /* 토글 이벤트 리스너 */ mode.addEventListener('click', function(){ localStorage.theme = mode.checked ? 'dark' : 'light'; darkTheme.disabled = mode.checked !== true; defaultTheme.disabled = mode.checked === true; changeGiscusTheme(); }); </script> <span class="bar"></span><section class="hero is-fullheight has-text-centered" id="post"><div class="hero-body"><div class="container"> <a href="/blog/mixmatchpaper" class="has-text-black" id="title"><h1 class="title has-text-centered is-2 has-text-weight-semibold ">MixMatch-A holistic approach to semi-supervised learning에 대하여</h1></a><hr class="has-background-black"><div class="columns is-variable is-5"><div class="column is-6"><figure class="image is-16by9 has-shadow"> <img src="https://user-images.githubusercontent.com/79881119/235352836-99c2a2ef-1197-4bb2-a730-1e48fcf60ded.jpg" alt="" id="post-image"></figure></div><div class="subtitle column is-5 has-text-left-desktop has-text-left-fullhd has-text-left-tablet has-text-center-mobile"><p id="description" class="content is-small has-text-weight-medium is-uppercase">paper review</p><p class="subtitle is-6 is-uppercase has-text-weight-normal has-text-black-ter">Published on <b>December 07, 2022</b> by <a href="https://github.com/6unoyunr" target="_blank"><b class="has-text-link"><u>JY</u></b> </a></p><p class="subtitle is-uppercase"> <i class="fa fa-tags"></i> <span class="tag is-link">SSL</span> <span class="tag is-link">AI</span> <span class="tag is-link">Deep learning</span></p><p class="subtitle is-uppercase"><i class="fa fa-clock"></i> <b class="has-text-link"> 11 min </b>READ</p></div></div><div class="content has-text-justified-desktop has-text-justified-fullhd has-text-justified has-text-justified-tablet has-text-left-mobile"><p><p>준지도학습이란 흔히 일부 레이블이 존재하는 데이터에 대해 학습한 모델을 토대로 레이블이 없는 데이터셋에 대해서 학습을 진행하는 것을 의미한다. 즉, unsupervised learning과 동일하게 representation mapping을 어떠한 방식으로 해결할 것인지에 대한 분석이 중요하며, 본 게시글에서는 SSL(Semi-supervised learning)에서 가장 성능을 끌어올렸던 유명한 논문 중 하나인 MixMatch에 대해 리뷰하도록 하겠다. <a href="https://arxiv.org/abs/1905.02249">논문링크</a></p><h1 id="deep-learning의-구성-요소">Deep learning의 구성 요소</h1><p>뜬금없이 딥러닝의 구성 요소를 언급하고자 한 이유는 바로 그 안에 supervised, semi-supervised 등 딥러닝 연구 분야에 대한 갈림길이 내재되어있기 때문이다. 딥러닝이 성공한 주요 이유는 머신 러닝의 한 기법 중 하나인 Neural Network를 보다 효율적인 형태로 구성하고, 이를 gradient based 방식으로 최적화하기 위해 SGD, Adam 등 다양한 optimization 방법이 제안되었다. 또한 ReLU function이나 residual learning과 같이 현재에도 SOTA로 쓰일 정도로 좋은 모델링 방법이 많이 연구되었고, 여전히 transformer 구조 및 multimodal 등 다양한 형태의 연구가 진행되는 중이다. 이러한 서사를 막론하고, 결국 우리가 목표로 잡는 학습을 cost function, objective function이라 부르고, 이를 최적화하기 위해서는 충분히 많은 데이터가 필요하다. 예를 들어 이미지 분류 작업같은 경우, 단순히 이미지를 n개의 class로 구분하는 지표화 작업이 필요하지만, segmentation과 같은 경우 이미지 각 픽셀에 대한 지표화가 필수적이고, 이런 경우 time consuming 문제가 있다. 다른 문제로는 만약 의학적인 지식이 필요한 상황이라면(의료 CT, MRI 이미지를 통한 진단 딥러닝 알고리즘을 설계하려고 한다면), 레이블링에는 충분히 많은 사전 지식(도메인 지식)이 필요하기도 하다. 또한 만약 어떠한 영상이나 이미지를 보고 등장하는 사람이나 사물에 대한 private information이 지표화에 필요할 경우, 사생활 문제가 야기될 수 있다. 결국 길게 말하고자 한 것은 방대한 데이터셋과 augmentation 방법으로 딥러닝 네트워크 파라미터로 하여금 보다 일반화에 가까운 representation을 학습한 것이 딥러닝이 좋은 성능을 낼 수 있는 키포인트인데, 이러한 데이터셋을 얻기 위한 과정이 순탄치가 않다는 것.</p><h1 id="ssl--semi-supervised-learning">SSL : Semi-Supervised Learning</h1><p>위에서도 사용했지만, 준지도 학습에 대한 단어는 SSL로 통일하도록 하겠다. 준지도 학습에서 지표화된 데이터셋의 필요를 줄이기 위해서 접근한 연구 방식은 모델로 하여금 unseen data에 대해 unlabeled dataset이 보다 일반화에 도움을 줄 수 있게끔 해주기 위한 “loss term”을 잘 설정하는 데에 있었다. 예를 들어 라벨링이 되어있지 않은 그림에 대해서 우리는 고양이 사진을 보고 당연히 “고양이”라고 오차 없이 예측할 수 있지만, 네트워크는 모든 분류 작업을 확률 기반(softmax)으로 계산하기 때문에 이러한 형태의 확신을 가지기 힘들다. 이는 이후 SSL을 MixMatch라는 알고리즘으로 접근한 해당 논문의 내용에서 더 자세히 다루도록 하고, loss term을 바꾸는 연구의 세 가지 큰 방식을 구분하도록 하겠다.</p><h2 id="entropy-minimization">Entropy minimization</h2><p>첫 번째는 Enropy minimization이다. 일반적으로 지표화가 진행되지 않은 데이터를 모델이 예측하면 확률값으로 매핑이 된다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059028-f13d36bd-c752-4c19-9cc8-b016185d4f75.jpg" /></p><p>만약 지표화가 된 상황에서의 데이터라면 “개, 고양이, 원숭이”의 3가지 클래스를 구분하는 작업에 있어서 1-hot encoding(이를 hard label이라고도 부른다)을 수행한다. One-hot encoding이란 정답인 확률이 1이고 나머지가 0인 상황이다. 따라서 위의 그림을 그대로 지표화하게 되면 (0, 1, 0)이 되는 것이다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059035-69102d07-26c6-48fb-9b8d-2b15aa0ac992.png" /></p><p>그러나 이를 네트워크에 통과시킨 결과는 다르다. 매우 잘 학습한 모델이 세 클래스에 대해 결과를 아무리 잘 예측하더라도 (0, 1, 0)이 되기 힘들다. 이는 cross entropy loss의 특성상 softmax를 포함하는 데에서 그 한계를 찾을 수도 있는데, 점수표가 어떤 방식으로 설정되든 이에 대한 CE loss를 계산하기 전 softmax 연산을 통해 확률값으로 매핑한다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059037-8d487115-45d6-46e6-88d7-920feb69f796.png" /></p><p>그러나 softmax 함수의 경우 0과 1을 점근선으로 가지기 때문에, 실제로는 점수표 상의 그 어떠한 value도 softmax 상에서 0과 1의 절대적인 값을 가질 수 없고, 결론적으로는 잘 학습된 모델의 경우에도 ‘고양이일 확률이 가장 높다’ 정도의 예측이 최선인 것이다. 결국 네트워크를 통과한 각 클래스에 대한 예측값은 확신이 없다고 볼 수 있는데, 이는 지표화되지 않은 데이터셋에 대해 학습을 하게 될 경우 문제가 생긴다. 그렇기 때문에 entropy minimization을 통해 애매한 확률값들을 확실한 값으로 바꿔준다. 이에 대한 내용은 이후 모든 loss term에 대해 설명한 후에 종합적인 분석이 필요한 부분이 있어 뒤로 넘기도록 하겠다.</p><h2 id="consistency-regularization">Consistency regularization</h2><p>두 번째는 Consistency regularization이다. 이는 생각보다 간단한 개념인데,</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059039-fb2d2135-7f02-46e5-b713-c73cb6a67e41.png" /></p><p>예를 들어 위와 같이 고양이 사진을 90도 회전시킨 augmented sample을 unlabeled dataset으로 사용한다고 생각해보자. 서로 다르게 augmented(노이즈 추가, 컬러 변경, 회전 등)된 두 이미지는 사실 서로 같은 probability distribution을 가져야 한다. 즉 지표화되지 않은 샘플에 대해 예측이 들쭉날쭉하게 변하지 않게 하는 것이 정규화 방식이다.</p><h2 id="generic-regularization">Generic regularization</h2><p>Model의 overfitting을 방지하는 정규화 방식으로, 이후 설명할 MixMatch에서의 MixUp과 관련이 있다. 예를 들어 두 이미지에 대해 지표화가 되어있다고 가정하자. 강아지의 경우 (1, 0, 0)의 라벨을 갖게 되고, 고양이의 경우 (0, 1, 0)의 라벨을 가지게 된다. 이 두 샘플에 대한 convex sample은</p><p>[ \theta \cdot cat + (1-\theta) \cdot dog,~(0&lt;\theta&lt;1) ]</p><p>라고 볼 수 있다. 여기서 convex sample이란 두 샘플을 convex set의 한 지점으로 보고, 그 사이를 보간하는 모든 sample이 포함되는 convex set의 정의를 그대로 따른다고 볼 수 있다. 이를 실제로 시각화하면,</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059042-6f90bb89-7f19-4a0f-b7cc-a8756fd5c746.png" /></p><p>이렇게 개냥이가 각각 50%씩 첨가된 샘플이 생성된다. 해당 샘플에 대한 라벨은 마찬가지로 convex sample과 같은 공식에 따라</p><p>[ \theta \cdot (0,\ 1,\ 0) + (1-\theta) \cdot (1,\ 0,\ 0)\ = (0.5,\ 0.5,\ 0) ]</p><p>이러한 방식을 MixUp이라 부른다. 앞서 여러 가지의 정규화 방식을 소개하였고, 이제 본격적으로 MixMatch에서 어떠한 방식을 통해 위와 같은 여러 알고리즘을 통합하여 준지도학습을 진행할 수 있었는지 천천히 소개하도록 하겠다.</p><h1 id="related-works">Related works</h1><p>준지도 학습의 경우 관련 내용이 좀 있는데, MixMatch 논문에서는 전혀 언급하지 않는 분야도 있다. 이 중에 가장 유명한 transductive model, graph-based model 그리고 generative model에 대해 간단하게 소개하도록 하겠다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059045-b04b1a3a-5b87-42c1-8b93-0d4ca790cc43.png" /></p><p>Transductive learning은 Inductive learning과 다르게, 각 노드(데이터셋)와 엣지(라벨)에 대해 일부 노드에 대한 엣지 정보만 가지고 나머지 노드에 엣지를 부여하는 작업이다. 따라서 그래프 개념으로 해석한 SSL 그 자체로 보면 된다. 그래프 based model도 비슷한 형태로 생각해주면 된다. 물론 위와는 다르게 노드와 엣지의 느낌이 약간 다른데, Graph-based modeling에서 각 노드를 데이터셋으로 보는 방식은 transductive learning에서 해석하는 것과 같지만, 엣지는 유사성을 나타낸다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059047-34b7ea16-352b-4d71-84f2-f5109687188d.png" /></p><p>간단하게 MNIST 데이터셋으로 기준을 보인다면, 같은 숫자일수록 그래프 상에서 엣지(선으로 표현된 부분)가 강하게 나타날 것이고 이는 곧 유사한 클래스의 데이터일수록 높은 유사도(그래프 상에서는 거리가 가깝다고 역으로 이해할 수 있다)를 보인다고 생각할 수 있다. 에너지 based로 생각하는 것, Hessian과 관련된 수식 증명의 경우 나중에 기회가 된다면 따로 다룰 것이고 오늘 언급할 페이퍼는 해당 내용을 신경쓰지 않기 때문에 넘어가도록 하겠다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059049-7a484a0f-631e-47a8-89a2-629b361e2fe9.png" /></p><p>Generative modeling 방식은 말 그대로 생성 모델링을 통해 heuristic한 준지도 학습을 진행하게 된다. 이를 테면 노이즈를 제거하는 방식이 될 수도 있고, 이미지에 color를 입히는 작업이 될 수도 있으며 perturbation(빈 부분, 손상된 부분)을 복원하거나 서로 다른 채널을 예측하는 형태로 진행된다.</p><hr /><h1 id="build-up-for-mixmatch">Build up for MixMatch</h1><p>Mixmatch를 언급하기 전에 관련된 준지도학습 관련 내용을 간단하게 언급했다. 위의 내용은 사실상 related works라고 보기는 힘들되, semi-supervised learning을 풀어가려는 다양한 방법론으로 제시가 되고 있다. 그렇다면 MixMatch에서 아이디어로 삼게 된 여러 알고리즘에 대한 기본 내용을 보다 자세히 언급하도록 하겠다. 그 중 가장 첫 번째는 Consistency regularization으로, Augmentation이 서로 다르게 적용되었다고 하더라도 같은 라벨을 예측해야한다는 것을 네트워크 학습에 이용하게 된다. 따라서 stochastic한 함수 Augment(x)가 존재하고, 만약 같은 input image X에 대해 랜덤한 augmentation을 적용하면, 이에 대한 parameterized 모델의 예측은</p><p>[ p_{model}(y \vert \text{Augment}(x); \theta), p_{model}(y \vert \text{Augment}; \theta) <br /> ]</p><p>와 같이 두 개로 나온다. 여기서 주의할 점은 Augment() 함수 자체가 stochastic하다고 했으므로, 두 개의 term은 서로 다른 예측값을 가진다(같은 value가 아님). 따라서 모델은 다음과 같은 loss term을 최소화하는 방향으로 학습된다.</p><p>[ \parallel p_{model}(y \vert \text{Augment}(x); \theta) - p_{model}(y \vert \text{Augment}; \theta) \parallel_2^2 ]</p><p>Mean Teacher 방식에서는 두 개의 term을 서로 다른 모델링을 통해 해결하는데, 바로 아래와 같은 그림을 보면 student model의 경우에는 똑같은 방식으로 최적화가 진행되지만, teacher model은 student model의 parameter를 exponential moving average 방식으로 가져와 사용한다. Exponential moving average를 잘 모른다면 그냥 단순히,</p><p>[ w_{k+1}^{teacher} = \beta w_k^{teacher} + (1-\beta)w_k^{student} <br /> ]</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059052-e06308cd-62b4-4969-8a05-1be0d97cb338.png" /></p><p>처럼 기존 weight에 student weight를 업데이트하는 방식을 사용한다고 생각하면 된다. 자세한 내용은 <a href="https://arxiv.org/abs/1703.01780">여기</a>를 참고. 그리고 VAT라는 방식(Virtual Adversarial Training)에서는 Adversarial sampling 방법 중에 maximally changes output class distribution을 이용한 perturbation 방식(모델을 가장 혼란스럽게 만드는 augmentation이라고 보면 된다)을 사용, hard sampling을 통해 같은 방식으로 최적화를 한다. MixMatch에서는 단순한 data augmentation 방식으로 볼 수 있는 random horizontal flips and crops를 사용한다.</p><p>두 번째는 엔트로피 최소화이다. 사실 그냥 Entropy minimization을 단순 번역한 것. 곰곰히 생각해보면 정보 이론에서 엔트로피가 어떤 식으로 정의되는지 혹시 기억할지 모르겠다. 만약 랜덤 변수 space X에서 각 랜덤 변수가 추출될 확률을 $P = (p_1, p_2, p_3, …)$ 등으로 정의한다면 해당 space에서의 엔트로피는</p><p>[ \begin{aligned} \text{for }X =&amp; (x_1,~x_2,~\cdots,~x_N)\text{ where each random variable }x_i(i=1,~\cdots,~N)\text{ has a probability }P = (p_1,~\cdots,~p_N), \newline H(X) =&amp; -\sum_{i=1}^N p_i \log(p_i) \end{aligned} <br /> ]</p><p>라 할 수 있다. 물론 지금 이 상황에서는 이산 확률에 대한 가정이지만, 결론적으로 말하자면 얼마나 분포가 고르냐/고르지 않냐의 문제로 귀결된다.</p><p>앞서 설명했던 바와 같이 지표화가 진행되지 않은 샘플에 대한 예측은 실제 one-hot encoding 방식에 비해 라벨링 자체의 엔트로피가 높게 생성된다. 또한 앞서 언급한 여러 data augmentation을 거친 샘플들에 대한 예측 결과는 더욱 entropy를 증가시키는 요인이 될 것이다.</p><p>이렇게 라벨 대신에 사용할 모델의 예측 확률값들을 Pseudo-Label이라 부르기로 했고, 우리는 이러한 유사 라벨들을 실제 학습에 활용하기 위해 다음과 같은 전략을 세운다.</p><ol><li><p>$K$개의 augmentation을 같은 데이터 $X$에 취한다.</p></li><li><p>각각의 augmented data $K$개를 모델에 통과시킨 예측 확률 map에 평균을 취하고, average label을 생성한다.</p></li><li><p>Average label에 앞서 언급한 entropy minimization을 수행한다.</p></li></ol><p>Sharp label을 만들기 위한 entropy minimization은 temperature hyperparameter $T$에 의해 결정된다. 일반적인 probability에,</p><p>[ Sharpen(p,~T)_i = \frac{p_i^{1/T}}{\sum^L_1 p_j^{1/T}} ]</p><p>이와 같이 적용한 새로운 확률 맵을 이용하는 것이다. 이를 실제로 시각화하여 보면 다음과 같다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059056-4f683a5d-ce95-4a72-8248-e3a1dd1abb4c.png" /></p><p>$T = 1$이면 원래의 확률 맵과 동일하다. 위와 같이 균등균등하게 설정한 확률 맵에서는 유사한 확률값(0.15, 0.13, 0.12)가 실제 모델 학습에서 dense region problem을 일으킬 수 있다. 이게 무슨 소리냐면,</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059057-a0ece861-efba-405b-b135-deb59f99f388.jpeg" /></p><p>위와 같은 그림에서, 진하게 표시된 십자가 모양과 삼각형 모양이 라벨링 된 데이터고 이에 대해 학습을 진행한 후에 unlabeld 샘플(파란색/주황색 점들)에 대해 decision boundary를 고려하는 상황이라면, 실선으로 나와있는 경계선보다 점선으로 나와있는 경계선이 분포 상으로 덜 밀집된 부분을 지나가기 때문에 적절한 경계선으로 보인다. 이렇듯 경계선이 밀도가 높은 지점을 지나게 되면, 해당 경계선 위치에 있는 샘플의 경우 보다 확률이 애매하게 매핑되기 때문에 이를 방지하기 위한 minimization 방법을 고안하게 된 것이다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059060-042b9c8c-5546-443b-bd44-6b8050fba5ca.gif" /></p><p>실제로 $T$값을 점차 감소시키면서 위의 식을 적용해보는 모습이다. $T$가 $0$에 가까워질수록 분포는 one-hot encoding에 가까워지고 $T \rightarrow 0$가 되면 one-hot encoding에 수렴한다.</p><figure class="half"> <img src="https://user-images.githubusercontent.com/79881119/209059063-258cba67-de1e-4de7-ada3-b6d32971acdb.png" width="600" /> <img src="https://user-images.githubusercontent.com/79881119/209059066-0e54d4e6-842d-4fc8-9ed7-3545f8d9a574.png" width="600" /></figure><h1 id="mixmatch-algorithm">MixMatch algorithm</h1><p>MixMatch 알고리즘이 사용하는 loss objective는 크게 두 가지로 구분된다. 준지도 학습을 구성하는 labeled dataset과 unlabeled dataset 각각에 대해 적용되는 loss(CE loss for labeled sample, consistency loss for unlabeled sample)이 서로 다르기 때문이다.</p><p>뒤이어 알고리즘 전반에 대해 디테일하게 설명하기 전에, $X’, U’$는 각각 labeled dataset으로부터의 augmented dataset 그리고 unlabeled dataset으로부터의 augmented dataset을 의미한다.</p><p>[ X’,~U’ = MixMatch(X, U, T, K, \alpha) <br /> ]</p><p>$X, U$는 augmentation이 진행되기 전 각 dataset을 의미하고 $T$는 entropy minimization에 사용되는 temperature, $K$는 unlabeled dataset에 적용될 augmentation 개수, $\alpha$는 MixUp에 사용될 convex coefficient에 해당된다.</p><p>[ L_X = \frac{1}{\vert X’ \vert} \sum_{x, p \in X’} H(p, p_{model}(y \vert x; \theta)) <br /> ]</p><p>당연하게도 라벨이 존재하는 데이터에 대해서는 원래의 label에 대한 cross entropy loss를 적용하게 되고,</p><p>[ L_U = \frac{1}{L\vert U’ \vert} \sum_{u, q \in U’} \parallel q-p_{model}(y \vert u; \theta) \parallel_2^2 <br /> ]</p><p>라벨이 존재하지 않는 데이터세 대해서는 pseudo label $q$를 적용한 consistency regularization loss를 사용한다. 이 두 개를 잘 섞어서 사용한다고 생각하면 된다. 사실 수식만 봐서는 아직 잘 이해가 안될 분들을 위해 직접 알고리즘 코드 한 줄 한 줄 설명해드리도록 하겠다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059068-c301914f-e460-4e6f-accd-0c745e74107f.png" /></p><p>1~6번째 줄을 먼저 보도록 하자. 입력으로는 같은 배치 크기의 labeled dataset과 unlabeled dataset을 사용하고, labeled dataset $x$에 대해서는 stochastic augmentation을 한 개 적용하고, unlabeled dataset $u$에 대해서는 stochastic augmentation을 $K$개 적용한다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059073-bbebd988-7b15-4cef-9606-556bb05ac16c.png" /></p><p>요 부분에서 pseudo label이 결정되는데, $K$개의 augmented된 unlabeled sample인 $\hat{u}$ 애들을 가지고 각각 모델의 예측값을 뽑아낸 뒤, 이를 $K$로 나누어 평균 예측값을 구하게 된다. 논문에서도 설명하겠지만 Pseudo-labeling 과정에 대해서는 최적화를 먹이지 않는다고 한다. 즉 오로지 현재 모델의 예측값을 기준으로 삼는다는 것. 그런 뒤 temperature hyperparameter $T$에 대해 sharpening을 진행하면 pseudo label $q_b$를 생성할 수 있게 된다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059075-530284c1-90de-4a4e-ab0f-9139e508f01f.png" /></p><p>10~12번째 줄은 label data(augmentation 이후) + unlabeled data(augmentation 이후)를 서로 합친 뒤에 셔플링하는 과정이다. 섞게 되면 총 $B + B \times K$개의 샘플이 무작위로 나열되고, 이를 하나의 queue 혹은 dequeue 자료형으로 생각한다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059078-b9d40da6-ec11-4bab-904f-dad2d09ae580.png" /></p><p>무작위로 나열된 샘플 배치 내에서 X’(labeled dataset)과 MixUp을 진행하고, 나머지 샘플들을 이용하여 U’(unlabeled dataset)과의 MixUp을 진행한다. 이렇게 진행된 MixUp은 lambda 값에 따라 labeled data 혹은 unlabeled data와의 중요도를 결정하는데, 만약 단순히 샘플링한 W를 MixUp에 사용하면, 구체적으로 labeled dataset과의 MixUp, 혹은 unlabeled dataset과의 MixUp에 대한 중요도가 사라지게 된다. 따라서</p><p>[ \begin{aligned} \lambda =&amp; Beta(\alpha,~\alpha) \newline \lambda’ =&amp; \max (\lambda,~1-\lambda) \newline x’ =&amp; \lambda’x_1 + (1-\lambda’)x_2 \newline p’ =&amp; \lambda’p_1 + (1-\lambda’)p_2 \end{aligned} ]</p><p>이와 같이 샘플을 MixUp하게 되면 Vanila MixUp(lambda를 서로 같은 값으로 둠)에서 무시했던 batch order를 유지하면서 MixUp sample를 생성할 수 있게 된다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059081-b3812560-90f9-4fed-954b-52d6519ecc9c.png" /></p><p>실제로 CIFAR-10, SVHN에 대해 250~4000 label를 가지고 SSL을 진행한 MixMatch 방식과 오차율을 비교하게 된다. Supervised method는 당연히 다른 방법들에 비해 좋은 것이 맞고, 검은색(제안된 방법)이 적은 라벨을 가지고도 representation을 효과적으로 학습할 수 있음을 보인다.</p><p align="center"> <img src="https://user-images.githubusercontent.com/79881119/209059086-cc8045b7-cc5a-4a0c-844e-f43dd1dfeba7.png" /></p><p>주요 contribution이라 함은 이런 저런 loss term과 관련된 SSL 방식을 최적화하는 알고리즘을 효율적으로 잘 설계했다는 점이 될 수 있겠다.</p></p></div></div></div></section><div class="contain_cats" align="center"><div class="contain_category" align="center"><div class="anothercat" align="center"><body><div class="waviy"> <span style="--i:1">A</span> <span style="--i:1">n</span> <span style="--i:1">o</span> <span style="--i:1">t</span> <span style="--i:1">h</span> <span style="--i:1">e</span> <span style="--i:1">r</span> <span style="--i:2"> </span> <span style="--i:2"> </span> <span style="--i:2"> </span> <span style="--i:3">p</span> <span style="--i:3">o</span> <span style="--i:3">s</span> <span style="--i:3">t</span> <span style="--i:4"> </span> <span style="--i:4"> </span> <span style="--i:4"> </span> <span style="--i:5">i</span> <span style="--i:5">n</span> <span style="--i:6"> </span> <span style="--i:6"> </span> <span style="--i:6"> </span> <span style="--i:7">c</span> <span style="--i:7">a</span> <span style="--i:7">t</span> <span style="--i:7">e</span> <span style="--i:7">g</span> <span style="--i:7">o</span> <span style="--i:7">r</span> <span style="--i:7">y</span></div></body></div><div class="adjacent"><div class="prev_btn"> <a id="prev" class="button" href="/blog/nsvf"><p id="prev_title"> ❮❮ NSVF-Neural Sparse Voxel Fields에 대해서</p></a></div><div class="next_btn"> <a id="next" class="button" href="/blog/efficient"><p id="next_title"> ❯❯ Efficient deep neural networks에 대하여</p></a></div></div></div></div><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script> <script> const title1 = $("#prev_title").text(); const title2 = $('#next_title').text(); var speed = 100; var dots = '⋯⋯'; var titlelength = function () { setInterval(function () { var ww = $(window).width(); if(ww < 400){ offset = 10; if(title1.length > offset){ part = title1.substr(0, offset); $("#prev_title").text(part + dots); } if(title2.length > offset){ part = title2.substr(0, offset); $("#next_title").text(part + dots) } } else if(ww < 600){ offset = 20; if(title1.length > offset){ part = title1.substr(0, offset); $("#prev_title").text(part + dots); } if(title2.length > offset){ part = title2.substr(0, offset); $("#next_title").text(part + dots) } } else{ $("#prev_title").text(title1); $("#next_title").text(title2); } }, speed); }; $(document).ready(function () { titlelength(); }); </script><div class="gitcus" id="gitcus_container"> <script src="https://giscus.app/client.js" data-repo="6unoyunr/comments" data-repo-id="R_kgDOODmwzQ" data-category="General" data-category-id="DIC_kwDOODmwzc4Cn5wD" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="ko" crossorigin="anonymous" async> </script></div><footer id="footer"> <!--Footer Button--><div class="container has-text-centered has-background-grey-darker" id="backtotop"> <a class="has-text-white" onclick="window.scroll(0,0)">BACK TO TOP</a></div><!--Footer Main Section--><div class="has-background-grey-darker"><div class="container columns"> <!--Name Section--><div class="column has-text-left-desktop has-text-centered-mobile"> <a href="http://localhost:4000/#about"><div class="columns"><div class="column is-one-fifth-desktop is-one-fifth-fullhd is-one-quarter-tablet"><figure class="image is-64x64"> <img class="is-rounded" src="https://avatars.githubusercontent.com/u/201962047?v=4"></figure></div><div class="column is-marginless"><h5 class="has-text-grey-lighter">JY</h5><div class="content has-text-grey"><p>I am an AI researcher with a strong interest in machine learning and dee...</p></div></div></div></a></div><!--Link Section--><div class="column has-text-white"><h3>More Links</h3><li> <a href="http://localhost:4000/category/development">DEVELOPMENT</a></li><li> <a href="http://localhost:4000/category/github%20blog">GITHUB BLOG</a></li><li> <a href="http://localhost:4000/category/paper%20review">PAPER REVIEW</a></li></div><!--Blog-post Section--><div class="column has-text-white"><h3>Recent Posts</h3><li> <a href="http://localhost:4000/blog/deepseekr1">딥시크(Deepseek)-R1에 대한 고찰. Thinking about Deepseek-R1 with Reinforcement Learning(RL).</a></li><li> <a href="http://localhost:4000/blog/mamba">Mamba modeling의 기초 (3) - Linear-Time Sequence Modeling with Selective State Spaces (Mamba)에 대하여</a></li><li> <a href="http://localhost:4000/blog/s4">Mamba modeling의 기초 (2) - (S4) Efficiently Modeling Long Sequences with Structured State Spaces에 대하여</a></li></div></div></div><div class="has-background-black has-text-centered has-text-white" id="credits"></div></footer></body></html><script> $(window).scroll(function() { var scrollY = ($(window).scrollTop() / ($(document).height() - $(window).height()) * 100).toFixed(3); $(".bar").css({"width" : scrollY + "%"}); }); </script>

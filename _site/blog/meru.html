<!DOCTYPE html><html><head><head> <!-- Include Meta Tags Here --><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta http-equiv="X-UA-Compatible" content="ie=edge"><meta name="viewport" content="width=device-width, height=device-height, initial-scale=1 user-scalable=no, shrink-to-fit=no"><meta content='#000000' name='theme-color'/><meta name="keywords" content="AI, Developer, Research engineer"><title>Welcome to my blog | MERU(Hyperbolic Image-Text Representations) 논문 리뷰</title><!-- Open Graph general (Facebook, Pinterest & Google+) --><meta name="og:title" content="Welcome to my blog | MERU(Hyperbolic Image-Text Representations) 논문 리뷰"><meta name="og:description" content="Vision Language Model, Hyperbolic Embeddings"><meta name="og:image" content="https://github.com/junia3/junia3.github.io/assets/79881119/dd292f21-4909-4ef2-a799-a288a99f0759"><meta name="og:image:alt" content="Welcome to my blog | MERU(Hyperbolic Image-Text Representations) 논문 리뷰"><meta name="og:url" content="http://localhost:4000/blog/meru"><meta name="article:author" content="https://www.facebook.com/"><meta name="og:site_name" content="Welcome to my blog | MERU(Hyperbolic Image-Text Representations) 논문 리뷰"><meta name="og:type" content="website"> <!-- Twitter --><meta property="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Welcome to my blog | MERU(Hyperbolic Image-Text Representations) 논문 리뷰"><meta name="twitter:description" content="Vision Language Model, Hyperbolic Embeddings"><meta name="twitter:site" content="@"><meta name="twitter:creator" content="@"><meta name="twitter:image:src" content="https://github.com/junia3/junia3.github.io/assets/79881119/dd292f21-4909-4ef2-a799-a288a99f0759"> <!-- Search Engine --><meta name="description" content="Vision Language Model, Hyperbolic Embeddings"><meta name="image" content="https://github.com/junia3/junia3.github.io/assets/79881119/dd292f21-4909-4ef2-a799-a288a99f0759"> <!-- Schema.org for Google --><meta itemprop="name" content="Welcome to my blog | MERU(Hyperbolic Image-Text Representations) 논문 리뷰"><meta name="author" content="JY"/><meta itemprop="description" content="Vision Language Model, Hyperbolic Embeddings"><meta itemprop="image" content="https://github.com/junia3/junia3.github.io/assets/79881119/dd292f21-4909-4ef2-a799-a288a99f0759"> <!-- Global site tag (gtag.js) - Google Analytics --> <script async src="https://www.googletagmanager.com/gtag/js?id=G-KFNS88G1GM"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'G-KFNS88G1GM'); </script><title>Welcome to my blog</title><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href=/assets/external/font-awesome-4.7.0/css/font-awesome.css><link rel="stylesheet" href="/assets/css/style_dark.css"><link rel="stylesheet" href="/assets/css/style.css"> <script src="https://kit.fontawesome.com/6a97161b76.js" crossorigin="anonymous"></script> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5834956759419182" crossorigin="anonymous"></script><link rel="apple-touch-icon" sizes="180x180" href="/assets/logo.ico/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/logo.ico/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/logo.ico/favicon-16x16.png"><link rel="mask-icon" href="/assets/logo.ico/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#FFFFFF"></head><script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } }, tex2jax: { inlineMath: [ ['$','$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\[','\]'] ], processEscapes: true, } }); MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) { alert("Math Processing Error: "+message[1]); }); MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) { alert("Math Processing Error: "+message[1]); }); </script> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script><div id="load"> <img src="/assets/images/loading.gif" alt="loading"></div><script > const loading_page = document.getElementById("load"); window.onload = function(){ loading_page.style.display = 'none'; } </script></head><body><nav class="navbar is-black is-fixed-top" role="navigation" aria-label="main navigation" id="navbar"><div class="container"> <!-- logo or branding image on left side --><div class="navbar-brand"> <a class="navbar-item" href="http://localhost:4000/"> <strong>Welcome to my blog</strong> </a><div class="navbar-burger" data-target="navbar-menu"> <span></span> <span></span> <span></span></div></div><!-- children of navbar-menu must be navbar-start and/or navbar-end --><div class="navbar-menu has-background-black" id="navbar-menu"><div class="navbar-end"> <a class="navbar-item " href="http://localhost:4000/">HOME</a> <a class="navbar-item" href="http://localhost:4000/#about">ABOUT</a> <a class="navbar-item" href="http://localhost:4000/#contact">CONTACT</a> <a class="navbar-item " href="http://localhost:4000/cv">CV</a> <a class="navbar-item " href="http://localhost:4000/blog">POST</a><div class="navbar-item has-dropdown is-hoverable"> <a class="navbar-link"> CATEGORY </a><div class="navbar-dropdown has-background-black is-left"> <a href="http://localhost:4000/category/deep%20learning" class="navbar-item has-text-grey-light "> DEEP LEARNING </a> <a href="http://localhost:4000/category/development" class="navbar-item has-text-grey-light "> DEVELOPMENT </a> <a href="http://localhost:4000/category/github%20blog" class="navbar-item has-text-grey-light "> GITHUB BLOG </a> <a href="http://localhost:4000/category/paper%20review" class="navbar-item has-text-grey-light "> PAPER REVIEW </a> <!--<hr class="navbar-divider"> <a class="navbar-item"> Report an issue </a> --></div></div><input id="darkmode_switch" class="mh_toogle" type="checkbox"> <label for="darkmode_switch" class="material-icons-sharp mh_toggle_btn"></label></div></div></div></nav><!-- Bulma Navbar JS --> <script> document.addEventListener('DOMContentLoaded', function () { /* Get all "navbar-burger" elements */ var $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0); /* Check if there are any navbar burgers */ if ($navbarBurgers.length > 0) { /* Add a click event on each of them */ $navbarBurgers.forEach(function ($el) { $el.addEventListener('click', function () { /* Get the target from the "data-target" attribute */ var target = $el.dataset.target; var $target = document.getElementById(target); /* Toggle the class on both the "navbar-burger" and the "navbar-menu" */ $el.classList.toggle('is-active'); $target.classList.toggle('is-active'); }); }); } }); </script> <script> /* 스타일 파일들 */ const defaultTheme = [...document.styleSheets].find(style => /(style.css)$/.test(style.href)); const darkTheme = [...document.styleSheets].find(style => /(style_dark.css)$/.test(style.href)); /* 스위치, 현재 테마 상태 불러오기 */ let mode = document.getElementById("darkmode_switch"); const current = localStorage.theme; /* 기존 상태에 따라 스위치 체크해주기 */ mode.checked = current === 'dark'; /* 체크된 거에 따라서 스타일 지정해주기 */ darkTheme.disabled = mode.checked !== true; defaultTheme.disabled = mode.checked === true; mode.addEventListener('click', function(){ localStorage.theme = mode.checked ? 'dark' : 'light'; darkTheme.disabled = mode.checked !== true; defaultTheme.disabled = mode.checked === true; }); </script> <span class="bar"></span><section class="hero is-fullheight has-text-centered" id="post"><div class="hero-body"><div class="container"> <a href="/blog/meru" class="has-text-black" id="title"><h1 class="title has-text-centered is-2 has-text-weight-semibold ">MERU(Hyperbolic Image-Text Representations) 논문 리뷰</h1></a><hr class="has-background-black"><div class="columns is-variable is-5"><div class="column is-6"><figure class="image is-16by9 has-shadow"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/dd292f21-4909-4ef2-a799-a288a99f0759" alt="" id="post-image"></figure></div><div class="subtitle column is-5 has-text-left-desktop has-text-left-fullhd has-text-left-tablet has-text-center-mobile"><p id="description" class="content is-small has-text-weight-medium is-uppercase">Vision Language Model, Hyperbolic Embeddings</p><p class="subtitle is-6 is-uppercase has-text-weight-normal has-text-black-ter">Published on <b>July 12, 2023</b> by <a href="https://github.com/6unoyunr" target="_blank"><b class="has-text-link"><u>JY</u></b> </a></p><p class="subtitle is-uppercase"> <i class="fa fa-tags"></i> <span class="tag is-link">VLM</span> <span class="tag is-link">CLIP</span> <span class="tag is-link">Multimodal</span> <span class="tag is-link">Hyperbolic space</span></p><p class="subtitle is-uppercase"><i class="fa fa-clock"></i> <b class="has-text-link"> 12 min </b>READ</p></div></div><div class="content has-text-justified-desktop has-text-justified-fullhd has-text-justified has-text-justified-tablet has-text-left-mobile"><p><h2 id="들어가며">들어가며…</h2><p>논문을 소개하기 전, <strong>CLIP</strong>과 <strong>ALIGN</strong>과 같은 기존 <strong>Vision-Language Modeling</strong>의 문제점을 짚는 것이 우선이다. 만약 두 논문에 대한 사전 지식이 없다면 <strong>MERU</strong> 라는 이름을 가지는 이 모델이 문제시하고자 했던 유클리디안 space(모든 datapoint에 대해 동일한 거리 기준을 삼는 것)에 대한 이해를 하기 힘들기 때문에 적어도 본인 블로그의 CLIP 논문에 대한 내용을 짚고 넘어오는 것이 좋다(<a href="https://junia3.github.io/blog/clip">참고 링크</a>).</p><p>유클리디안 기하학과 비유클리디안 기하학은 다른 거리 기준을 가진다. 예컨데 유클리디안(이를 보통 평평한 평면에 비유하기도 함) 공간에서는 삼각형의 세 내각의 합이 $180^\circ$ 인 것이 당연하지만, Spherical 공간에서는 성립하지 않는 것을 볼 수 있다. 마찬가지로 Modality가 놓인 공간이 얼마나 휘어있느냐(이를 하이퍼볼릭에서는 <strong>Curvature</strong>라는 값으로 정의함)에 따라 각 임베딩 간의 관계성이 다르게 성립한다.</p><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/49ca4af0-721d-4307-901f-0d3300f6c53a" width="700" /></p><p>논문에서는 다행(?)인지 모르겠지만 수식을 방대하게 풀어놓는 형태로 우리를 괴롭히지는 않는다. 다만 단순하게 요약해서 ‘이미지/텍스트’ 간의 관계성을 설명하는 기하학은 <strong>Euclidean</strong>이 아닌 <strong>non-Euclidean</strong>이 보다 적합하다는 것. 그렇다면 대체 어떤 이유에서 기존 VLM과 다르게 다른 기하학을 도입하고자 하였는지 살펴보도록 하자.</p><hr /><h2 id="텍스트와-이미지의-계층적-관계">텍스트와 이미지의 계층적 관계</h2><p>예컨데 다음과 같은 이미지가 있다고 생각해보자.</p><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/8c03e96b-8cc5-4507-84f5-16d205f84d25" width="300" /></p><p>길거리에 나가 $n$명의 사람들에게 “이 그림을 한 문장으로 요약해주시거나, 느낀 점을 말씀해주세요.” 라고 부탁해보자. 도를 아십니까로 착각하여 내치고 지나가지 않는 이상 $n$명의 사람들은 서로 다른 대답을 할 것이다. 예컨데 다음과 같은 후보군이 있을 수 있다.</p><ul><li>강아지와 고양이 사진입니다.</li><li>고양이가 강아지한테 덤비고 있네요.</li><li>너무 귀여운 사진이네요.</li></ul><p>사람이 이미지와 텍스트를 인지하는 과정은 말하지 않더라도 자연스럽다. 이미지와 텍스트와의 관계성을 고려할 때 우리는 내재된 ‘계층적 관계’를 이해할 수 있다는 것이다. 위에서 예시로 든 첫번째 문장과 두번째 문장을 비교해보자. ‘강아지와 고양이 사진입니다.’라는 설명은 단순히 이미지에 속한 semantic한 정보만을 고려한다. 말 그대로 이미지에 ‘강아지’와 ‘고양이’라는 객체가 포함되어 있다는 정보만 줄 뿐 두 객체의 관계성에 대해서는 설명하지 않는다. 그럼에도 불구하고 ‘강아지와 고양이 사진입니다.’는 이미지를 잘 설명하는 텍스트에 해당되고, 우리가 설계하고자 하는 이미지/텍스트 간의 관계성 메트릭 공간에서는 서로 가까운 거리를 유지해야할 것이다.</p><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/264f318b-377c-4961-a59f-e2221380d7b6" width="300" /> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/f540a4fe-0326-4bd0-a623-c19fc2a7b4dc" width="300" /></p><p>‘고양이가 강아지한테 덤비고 있네요.’라는 문장은 단순히 객체만을 묘사하지 않고 두 객체 간의 관계에 대한 정의를 내리고 있다. 실제로 이미지만 보고서 고양이가 강아지한테 덤비고 있다는 사실 여부까지는 확인할 수 없지만, 적어도 ‘고양이가 강아지한테 덤비고 있네요.’라는 문장이 해당 이미지를 묘사할 수 있는 합리적인 결과물이라고 인지할 수 있다. 마찬가지로 우리가 설계하고자 하는 이미지/텍스트 간의 관계성 메트릭 공간에서는 서로 가까운 거리를 유지해야할 것이다. 위의 그림 상에서 초록색으로 표시된 부분이 곧 그 관계성을 표현하는 부분이라고 할 수 있다.</p><p><strong>‘그래서 하고픈 말이 뭔데?’</strong>라고 물어볼 당신을 위해 마지막 문장을 예시로 들면서 언어의 계층적 구성에 대해 언급하고자 한다. ‘너무 귀여운 사진이네요’라는 표현 자체는 큰 문제가 없다. 그나마 문제시될 만한 점은 고양이랑 강아지를 그다지 귀여워하지 않는 사람도 있다는 것인데, 그런 사소한 취향 차이는 무시하고 고양이랑 강아지는 무조건 귀여운 존재라는 가정 하에 각 표현력이 가지는 정보를 계층적으로 구성하면 다음과 같다.</p><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/f9588315-c25b-461d-a4f3-8d94386dca0f" width="700" /></p><p>텍스트가 묘사하는 내용이 보다 이미지에 특화될수록(이미지에 잘 부합할수록), 그만큼 이미지에서 디테일하게 볼 semantic한 정보에 대한 공간력의 크기 또한 달라지게 되는 것이다. 이걸 단순히 유클리디안 공간에서 표현하게 되면 이미지를 묘사하는 모든 문장들과의 관계성이 cosine similarity(벡터의 각도)에 대해서만 정의되기 때문에 계층적으로 구성된 임베딩을 전혀 고려하지 않게 된다.</p><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/035705b2-9769-4328-bc8c-2b9ec868bb59" width="300" /></p><p>왜냐하면 기존 VLM이 baseline으로 가져가는 contrastive learning objective에는 거리 메트릭이 <strong>오직 embedding 유사성에만 의존</strong>하기 때문이다.</p><hr /><h2 id="하이퍼볼릭-공간에-대한-짧은-recap">하이퍼볼릭 공간에 대한 짧은 Recap</h2><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/da718e50-f62e-46d5-bbeb-bf4465c788d5" width="800" /></p><p>사실 비유클리디안 모달리티를 표현하기 위한 하이퍼볼릭 geometry에 대한 연구는 이전에도 꾸준히 진행되었다. 계층적 임베딩을 학습하기 위해 정의한 푸앙카레 disk(혹은 확장한 ball)에 대해 정의한 paper(<a href="https://papers.nips.cc/paper/2017/file/59dfa2df42d9e3d41f5b02bfc32229dd-Paper.pdf">참고 링크</a>)을 먼저 살펴볼 수 있다. 푸앙카레 곡면이 가지는 특징은 우리가 매핑하고자 하는 쌍곡면(하이퍼볼릭) 공간의 모든 점을 해당 곡면 상으로 projection이 가능하다는 점이다. 사영할 때의 관계성만 정의된다면(각각의 점을 Analytic한 위상 함수의 $X, Y$ 위상 각각의 집합이라고 보면 된다) 임베딩을 푸앙카레 곡면에서 이해할 수 있다.</p><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/7a663341-0a21-4545-a5d1-dcca132e50c7" width="700" /></p><p>쌍곡면 공간의 이점은 곧 비유클리디안 모달리티의 대표적 형태인 ‘그래프’의 왜곡과 관련된다(<a href="https://chumji.tistory.com/3">도움될만한 링크</a>). 이에 대한 내용은 <a href="https://arxiv.org/abs/2011.14211">‘Curvature Regularization to Prevent Distortion in Graph Embedding’</a>에 잘 정리되어있는데, 간단하게 보자면 위의 그림에서 <strong>A</strong>와 같은 노드/엣지 관계를 가진 데이터를 고려해보자. 단순히 파란색으로 표현된 노드와 빨간색으로 표시된 노드에 대한 node classification 이외에도, 각 노드들의 연결성(어떤 노드와 엣지로 관련을 가지는지)에 따라 각각의 모달리티는 특정 표현자(embedding)를 가지면서 학습될 것이다. 기존 그래프 구조의 학습법의 경우 proximity preserving(인접한 노드일수록, 임베딩 유사성을 높게 가져간다)라는 목적 함수를 가지기 때문에 인접한 노드 간의 유사성 매핑과는 별개로 동떨어진 노드 간의 representation에 대해서는 아무런 고려를 하지 못한다(노드가 넘어갈수록 diffusion process와 같은 random walk를 생각하면 된다). 결론적으로 모든 노드들의 확률 그래프는 central limit theorem에 의해 가우시안 분포를 따르게 되어, 얼추 <strong>B1</strong>에서 보이는 것과 같이 둥그스럼한 형태의 임베딩 space를 구성하게 된다. 노드 간의 유사성을 고려한 mapping 방법 자체는 크게 잘못되지는 않았으나 기존에는 멀었던 노드들의 관계성이나 그래프 자체의 구조를 전혀 고려하지 못한다는 문제가 발생한다.</p><p>B1에서의 mapping법(Proximity Preserving을 목적으로 학습된 경우)와 B2에서의 mapping 법에 대해 distance를 기준으로 비교하면, <strong>Geodesic distance</strong>와 <strong>Shortest path distance</strong>는 두 경우 모두 유의미한 양의 상관관계를 가지지만(그림 <strong>C</strong>), <strong>Euclidean distance</strong>에서는(그림 <strong>D</strong>) 경향성이 무너지는 것을 확인할 수 있다. 하지만 Oracle Embedding으로 가정한 매핑 방법이 완벽하게 존재할 수는 없고, 임베딩 공간을 objective function으로 수렴시키고자 하는 딥러닝 메소드에서는 이런 학습법을 찾을 수 없는 것이 당연하다. 바로 이러한 <strong>학습법의 제약을 위상에 대한 제약으로 바꾸어 학습하고자 하는 것이 하이퍼볼릭 임베딩 리만 학습법이다</strong>.</p><hr /><h2 id="riemannian-manifolds리만-다양체">Riemannian manifolds(리만 다양체)</h2><p>부드러운 다양체는 일종의 부드러운 천을 생각하면 생각하기 편하다. 부드러운 천이 평평한 바닥에 놓여있다면 이는 곧 유클리디안 space에서의 리만 다양체가 될 것이고, 그렇지 않다면 일반화된 space 상에서의 다양체가 된다. 다양체라고 하니까 기분이 좀 이상하네 걍 manifold로 쓰는게 나을듯.</p><p>암튼 Smooth surface에 대한 Manifold를 생각해보면 결국 2차원의 sheet가 이리저리 얽혀있다고 보면 되고, 우리가 특정 함수를 해석학적으로 읽을 때의 느낌과 비슷하게 smooth surface 또한 Locally Euclidean(아주 작은 양수 $\epsilon$에 대해서 manifold를 확장시키면 해당 공간은 로컬 좌표계에서 유클리디안 모달리티를 가질 수 밖에 없다. $d\vec{x}*d\vec{y}$ 느낌으로다가)</p><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/894b0e78-4223-4da1-ad54-f0e0117f0364" width="300" /></p><p>그렇다면 Riemannian manifold를 정의하기 위해서는 딱 두 가지만 있으면 되는데 그게 바로 위에서 언급한 smooth manifold $\mathcal{M}$ 그리고 manifold 상에서 거리를 잴 수 있는 metric $g$이다. 고로 이 메트릭을 Euclidean inner product로 정의해버리면 그 Riemannian manifold는 곧 유클리디안 space로 수렴하는 것. 바로 <strong>기존 방식인 CLIP 학습법</strong>이 <strong>manifold는 implicit</strong>하게 가져가면서 metric $g$(이미지 임베딩과 텍스트 임베딩 간의 거리)를 <strong>Euclidean inner product(</strong>코사인 유사도<strong>)</strong>로 정의해버린 것과 같다.</p><p>하지만 제목에서부터 알 수 있듯이 이 논문의 목적은 하이퍼볼릭 space이고 하이퍼볼릭 space의 특징은 manifold가 ‘constant negative curvature’를 가진다는 점이다. 앞서 이런저런 소개를 통해 여러 모델링을 언급했지만 MERU 페이퍼에서는 차원을 하나 확장시켜서 해당 위상의 부분 위상으로서 정의되는 로렌츠 모델(Lorentz model)을 기반으로 한다.</p><hr /><h2 id="로렌츠-모델에-대한-하이퍼볼릭-공간적-정의">로렌츠 모델에 대한 하이퍼볼릭 공간적 정의</h2><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/3172e43f-b0f0-4abc-aa7c-e2f673008b7b" width="" /></p><p>MERU는 로렌츠 모델을 기반으로 한다. 로렌츠 모델을 머리 속에 그릴 때는 고등학교 때 배웠던(요즘도 배우나..?) 이차 곡선 중 쌍곡선에 대한 그래프를 $x$축을 기준으로 회전시켰다고 보면 된다. 이때의 $x$축이 additional axis을 의미하게 되며, 해당 공간 상의 텐서를 <code class="language-plaintext highlighter-rouge">permute</code> 시키게 되면 위에서 보는 것과 같이 $\mathbb{R}^{3}$ 공간에서의 두 smooth manifold 중 upper half를 볼 수 있게 된다($z &lt; 0$인 부분은 무시). 이때 hyperboloid의 중심이 되는 축(대칭축이라고도 부른다)인 $z$를 기존 수학 및 물리학에서 정의하는 것과 같이 시간에 대한 차원(time dimension)으로 정의할 수 있고, 이를 제외한 나머지 $n$개의 차원은 공간에 대한 차원(space dimension)으로 정의할 수 있다. 고로 위상의 모든 벡터는 $\rm{x}_\text{space} \in \mathbb{R}^n$이고 $x_\text{time} \in \mathbb{R}$인 좌표 $[\rm{x}_\text{space}, \it{x}_\text{time}]$로 벡터를 표현할 수 있다. 모든 수식에 서 로마 문자($\rm{x}, \rm{y}$)로 표현된 친구들은 2차원 이상의 좌표계를 가지는 벡터를 의미하고 이텔릭($x, y$)로 표현된 친구들은 1차원의 스칼라 값을 의미한다. Riemannian manifold를 구성하기 위해 필요한 smooth sheet는 마련되었고, 남은 건 거리 메트릭이다. 거리 메트릭은 Euclidean inner product인 $\left&lt; \cdot, \cdot \right&gt;$에 대해 다음과 같이 정의된다.</p><p>[ \left&lt; \rm{x}, \rm{y} \right&gt;_\mathcal{L} = \left&lt; \rm{x}_\text{space},\rm{y}_\text{space} \right&gt; - x_\text{time} y_\text{time} ]</p><p>마찬가지로 로렌츠 norm은 inner product에 대해 $\parallel \rm{x} \parallel_\mathcal{L} = \sqrt{\vert \left&lt; x, x \right&gt;_\mathcal{L} \vert}$ 로 유도된다. 고등학교 수학을 열심히 들었다면 쌍곡선의 특성에 대해서 잘 알고 있겠지만, 이차곡선의 방정식을 전미분하여 curvature를 구할 수 있고 <strong>해당 curvature에 해당되는 음의 scalar value $-c$</strong>에 대해 로렌츠 모델 상의 모든 벡터 조건(constraints)을 다음과 같이 줄 수 있다.</p><p>[ \begin{aligned} &amp;\mathcal{L}^n { \rm{x} \in \mathbb{R}^{n+1}: \left&lt; x, x \right&gt;_\mathcal{L} = -1/c,c &gt; 0 } \newline &amp;x_\text{time} = \sqrt{1/c + \parallel \rm{x}_\text{space} \parallel^2} \end{aligned} ]</p><p>이제 로렌츠 모델링을 통한 리만 다양체를 구성하는 과정이 거의 마무리되었다.</p><hr /><h2 id="로렌츠-모델링에서의-거리-메트릭">로렌츠 모델링에서의 거리 메트릭</h2><h3 id="geodesics">Geodesics.</h3><p>Geodesic은 다양체 내부의 두 점에 대해 가장 짧은 path를 의미한다.</p><p>질량이 없는 빛이 중력 가속도의 영향을 받아 휜다는 상대성 이론의 설명에서 휘어진 시공간을 통해 빛이 진행하는 얘기를 들어본 적이 있을 것이다. 우주 공간을 하나의 리만 다양체로 생각하고 만약 이 다양체가 여러 천체의 상호작용에 의해 휘어진 천과 같이 구성되어 있다면 직진하는 성질을 가진 빛은 사실 직진하는 성질을 가지는 것이 아니라 목표 지점까지 최단 루트로 가는 것과 같다. 바로 이렇게 빛이 그리는 궤도를 Geodesics라고 이해해볼 수 있다. 로렌츠 모델에서의 Geodesics는 hyperboloid와 두 벡터 및 원점이 그리는 평면의 intersection curve에 해당된다.</p><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/3f65ef46-9654-4306-b4bf-ab52ce7b0a42" width="700" /></p><p>이를 유도해서 풀면</p><p>[ d_\mathcal{L}(\rm{x}, \rm{y}) = \sqrt{1/c} \cdot \cosh^{-1}(-c \left&lt; \rm{x}, \rm{y} \right&gt;_\mathcal{L}) ]</p><h3 id="tangent-space">Tangent space.</h3><p>로렌츠 공간의 spacial vector $z$에 대해 tangent space는 해당 벡터와 Lorentzian inner product(앞에서 정의했던거)가 $0$이 되는 모든 모든 벡터가 모인 공간(span)이다. 해당 공간은 Euclidean space가 된다.</p><p>[ \mathcal{T}_{\rm{z}} = { \rm{v} \in \mathbb{R}^{n+1}: \left&lt; z, v\right&gt;_\mathcal{L} = 0 } ]</p><p>따라서 Ambient space(특정 차원의 공간을 포함하는 그 이상의 모든 공간을 의미한다)의 모든 벡터 $\rm{u}$는 orthogonal projection을 통해 저차원 공간인 Tangent space로 사영할 수 있다.</p><p>[ \rm{v} = \text{proj}_{\rm{z}}(\rm{u}) = \rm{u} + \it{c}\rm{z} \left&lt;\rm{z},\rm{u} \right&gt;_\mathcal{L} ]</p><h3 id="exponential-and-logarithm-maps">Exponential and logarithm maps.</h3><p>Exponential map은 tangent space의 벡터들을 manifold 상으로 올려주는 역할을 한다. 위에서 언급한 projection의 역과정은 아니고, ambient space가 아닌 공간에 대한 sub-space에서 공간 차원에 대한 벡터를 통해 함수 및 역함수를 구하는 과정이라고 생각해볼 수 있다.</p><p>[ \begin{aligned} &amp;\text{expm}_{\rm{z}} : \mathcal{T}_{\rm{z}}\mathcal{L}^n \rightarrow \mathcal{L}^n \newline \rm{x} = \text{expm}_{\rm{z}}(\rm{v}) &amp;= \cosh(\sqrt{c} \parallel v \parallel_\mathcal{L})\rm{z} + \frac{\sinh (\sqrt{c} \parallel v \parallel_\mathcal{L})}{\sqrt{c}\parallel v \parallel_\mathcal{L}}\rm{v} \end{aligned} ]</p><p>뒤에서 보면 알겠지만 실제 MERU에서는 space component만 써먹는 단순화 작업을 통해 하이퍼볼릭 코사인 텀 하나를 날려버린다. 하이퍼볼릭 함수는 모두 역함수가 있어서 반대로 manifold 상에서 tangent 공간으로 내리는 공식도 가능하다.</p><p>[ \begin{aligned} &amp;\text{logm}_{\rm{z}} : \mathcal{L}^n \rightarrow \mathcal{T}_{\rm{z}}\mathcal{L}^n \newline \rm{v} = \text{logm}_{\rm{z}}(\rm{x}) &amp;= \frac{\cosh^{-1}(-c\left&lt;\rm{z},\rm{x} \right&gt;_\mathcal{L})}{\sqrt{(c\left&lt; \rm{z}, \rm{x} \right&gt;_\mathcal{L})^2-1}} \text{proj}_{\rm{z}}(\rm{x}) \end{aligned} ]</p><hr /><h2 id="방법론">방법론</h2><p>모델링은 CLIP과 같이 이미지와 텍스트가 독립적인 인코더를 가지는 형태가 된다. 그런데 이제 여기서 그칠게 아니고 실질적으로 이 논문이 제시한 문제점을 해결하기 위해서는 다음과 같은 방법론을 적용해야한다.</p><ol><li>임베딩을 Euclidean space가 아니라 Lorentz space로 바꿀 방법</li><li>CLIP과 같이 이미지의 semantic 정보와 텍스트의 semantic 정보를 함께 학습할 방법</li></ol><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/815465e8-ecce-4142-9728-3ccc5692bb5e" width="600" /></p><h3 id="lifting-embeddings">Lifting embeddings</h3><p>임베딩을 올리는 방법은 다음과 같다. $n$차원으로 나온 이미지 및 텍스트 임베딩이 있다고 해보자. 기존 CLIP과 동일한 프레임워크라면 두 임베딩은 같은 형태의 텐서가 될 것이다. 로렌츠 모델은 설명했던 바와 같이 추가된 축(시간축)으로 확장시키는 작업이 필요하기 때문에, 우선은 임시로 원점에서의 tangent space(Euclidean)에 대한 벡터를 구한 뒤 이를 hyperboloid로 올리는 공식($\text{expm}$)을 적용하면 된다.</p><h3 id="expand-dims">Expand dims</h3><p>[ \rm{v} = (\rm{v}_\text{enc}, 0) \in \mathbb{R}^{n+1} ]</p><h3 id="onto-hyperboloid">Onto <strong>Hyperboloid</strong></h3><p>여기는 잘보면 우리가 지금 올려놓은 tangent space가 $\rm{z} = 0$에 기반하므로 하이퍼볼릭 코사인이 없어져도 된다.</p><p>[ \rm{x}_\text{space} = \frac{\sinh (\sqrt{c} \parallel v \parallel_\mathcal{L})}{\sqrt{c}\parallel v \parallel_\mathcal{L}} \rm{v}_\text{space} ]</p><p>그리고 <strong>시간에 대한 스칼라</strong>는 <strong>쌍곡면의 곡면에 대한 constraints</strong>로 구할 수 있다.</p><p>[ \begin{aligned} &amp;\mathcal{L}^n { \rm{x} \in \mathbb{R}^{n+1}: \left&lt; x, x \right&gt;_\mathcal{L} = -1/c,c &gt; 0 } \newline &amp;x_\text{time} = \sqrt{1/c + \parallel \rm{x}_\text{space} \parallel^2} \end{aligned} ]</p><p>즉 기존의 CLIP embedding을 하이퍼볼릭 embedding으로 바꾸는 작업 끝.</p><h3 id="numerical-issue">Numerical Issue</h3><p>다만 문제가 되는 점은 기존 임베딩 벡터를 하이퍼볼릭으로 올리면서 exponential 계산이 추가되는데, CLIP 기반의 weight 초기화가 진행된 경우 유클리디안 공간 벡터의 norm은 대략 $\sqrt{n}$을 가지게 된다. 그 말인 즉슨 이걸 exponential하게 올리면 수치적으로 $e^{\sqrt{n}}$가 초기값이 되어 학습이 불안정해지기 때문에 이를 해결할 방법이 필요하다. 그래서 이걸 해결하기 위해 scaling 스칼라인 $\alpha$를 각각 이미지 및 텍스트 임베딩 output에 적용하여 이러한 문제를 해결한다. 알파는 학습 가능한 파라미터.</p><h3 id="entailment-loss">Entailment loss</h3><p>Entailment loss는 CLIP에서 임베딩 관계성을 implicit하게 학습하기 위해 사용되는 contrastive loss에 추가적으로 하이퍼볼릭 공간의 위상 특성을 고려하여 이미지-텍스트 관계를 더해주는 역할이다.</p><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/02791678-6b37-463d-b9aa-add215050aa8" width="600" /></p><p>그림을 보면 알겠지만 각도에 대한 내용이기 때문에 로렌츠 모델을 위에서 내려다본 구조를 생각하면 되고, 예를 들어 특정 텍스트가 존재할 때 해당 텍스트가 반영하는 모든 이미지 임베딩의 공간을 aperture로 가정하면(원뿔 형태), 만약 이미지가 이 내부에 들어와있다면 굳이 끌어들일 필요가 없지만(이는 아마도 각도가 too much align되면 embedding collapse가 발생하여 representation이 subfold된다고 생각한 것으로 예상) 외부에 있다면 각도를 줄여주는 loss를 통해 aperture 내부로 임베딩을 끌어들이는 것이다. 서로 다른 이미지/텍스트를 인코딩한 임베딩 간의 거리 조절은 contrastive learning에서 주로 담당하고 있고, entailment loss는 하이퍼볼릭의 curvature를 고려하여 계층적 구조를 탄탄히 하려는 목적인 듯하다. <strong>모델링이 생각보다 너무 심플해서 놀랐던 부분</strong>.</p><p>[ \mathcal{L}_\text{entail}(\rm{x}, \rm{y}) = \max (0, ext(\rm{x},\rm{y})-\text{aper}(\rm{x})) ]</p><hr /><h2 id="experimental-results">Experimental Results</h2><h3 id="imagetext-retrieval">Image/Text retrieval</h3><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/b17fe799-0866-4b7f-be74-b66cc2e92f05" width="500" /></p><p>전반적으로 retrieval 성능을 CLIP에 비해 끌어올린 것을 볼 수 있는데, 확실히 유클리디안에서 비유클리디안으로의 공간 확장이 가지는 장점이 가장 잘 드러날 수 있는 실험 결과가 아닐까 생각된다.</p><h3 id="zero-shot-image-classification">Zero-shot image classification</h3><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/d7022668-571a-4af3-8312-b96060a7e9ad" width="700" /></p><p>Representation 학습에는 어떤 도움이 되는지. Retrieval 결과가 본인들 모델링에 대한 근본적 main contribution을 보여주는 실험이었다면 이건 비교적 sub contribution을 보여주는 결과라고 본다. 그래서 그런지 SOTA를 찍을 필요는 없고 성능 향상의 가능성만 간단하게 보여주고 넘어가는 듯.</p><h3 id="ablations">Ablations</h3><p>이런저런 ablation도 많이 진행했다. Qualitative results도 많다.</p><p align="center"> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/2e16b187-df91-4b46-b56e-a61f1acc487a" width="400" /> <img src="https://github.com/junia3/junia3.github.io/assets/79881119/91e6f21f-360e-4483-bb5d-e78e8ccd6c5b" width="400" /></p><p>좌측은 임베딩 길이에 따라 성능 본 것. 길이랑 무관하게 모두 성능이 좋게 나왔다. 우측은 논문에서 제시한 방법론들을 하나씩 빼고 한 것. Curvature를 고정하는 건 원래 푸앙카레 기법에서 사용한 것인데 그렇게 하면 놀랍게도 Large model에서 성능이 개판이 되는 걸 볼 수 있다. Contrastive learning 시에 Large model에서 로렌츠 norm을 사용하지 않으면 심지어 수렴이 되지 않고 발산을 하는데, 이는 아마도 트랜스포머 백본과의 수렴 속도 차이 때문의 문제로 생각된다.</p><hr /><h2 id="discussion-and-conclusion">Discussion and conclusion</h2><p>CLIP의 retrieval 및 linear probing/fine tuning 등 representation 자체를 모달리티 robust하게 만들고자 여러 연구가 나오고 있는 중인 것 같다. 그와 동시에 이미지와 텍스트 간의 semantic한 정보들을 보다 풍부하게 제공할 수 있는 학습 objective나 constraints를 제시하는 것이 앞으로의 multimodal task에서 가장 challenging한 부분이 되지 않을까 싶다.</p><p>MERU에서 제시한 로렌츠 모델링에 contribution이 있는 것은 아니고 기존 CLIP representation을 확장시킬 수 있는 방향을 제시한 것이 contribution로 보인다. Hyperbolic Riemannian manifold를 위한 모듈을 기존 framework 끝부분에 사용하고, 새로운 manifold에서 제시할 수 있는 추가적인 objective를 제시한 방향도 paper contribution에 적합하다고 생각했다. 기존 인코딩 방식을 바꾸지 않으면서 projection하는 방법만 제시했기 때문에 비슷한 형태의 embedding을 추출하는 인코더 기반 네트워크들에 대해 hierarchy embedding에 대한 추가 실험 및 연구가 진행되면 해당 방법론에 대한 정당성이 조금씩 확립될 것으로 보인다.</p></p></div></div></div></section><div class="contain_cats" align="center"><div class="contain_category" align="center"><div class="anothercat" align="center"><body><div class="waviy"> <span style="--i:1">A</span> <span style="--i:1">n</span> <span style="--i:1">o</span> <span style="--i:1">t</span> <span style="--i:1">h</span> <span style="--i:1">e</span> <span style="--i:1">r</span> <span style="--i:2"> </span> <span style="--i:2"> </span> <span style="--i:2"> </span> <span style="--i:3">p</span> <span style="--i:3">o</span> <span style="--i:3">s</span> <span style="--i:3">t</span> <span style="--i:4"> </span> <span style="--i:4"> </span> <span style="--i:4"> </span> <span style="--i:5">i</span> <span style="--i:5">n</span> <span style="--i:6"> </span> <span style="--i:6"> </span> <span style="--i:6"> </span> <span style="--i:7">c</span> <span style="--i:7">a</span> <span style="--i:7">t</span> <span style="--i:7">e</span> <span style="--i:7">g</span> <span style="--i:7">o</span> <span style="--i:7">r</span> <span style="--i:7">y</span></div></body></div><div class="adjacent"><div class="prev_btn"> <a id="prev" class="button" href="/blog/glide"><p id="prev_title"> ❮❮ GLIDE(Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models) 논문 및 코드 리뷰</p></a></div><div class="next_btn"> <a id="next" class="button" href="/blog/continual"><p id="next_title"> ❯❯ Continual learning/Lifelong learning의 개념과 방법론 총정리</p></a></div></div></div></div><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script> <script> const title1 = $("#prev_title").text(); const title2 = $('#next_title').text(); var speed = 100; var dots = '⋯⋯'; var titlelength = function () { setInterval(function () { var ww = $(window).width(); if(ww < 400){ offset = 10; if(title1.length > offset){ part = title1.substr(0, offset); $("#prev_title").text(part + dots); } if(title2.length > offset){ part = title2.substr(0, offset); $("#next_title").text(part + dots) } } else if(ww < 600){ offset = 20; if(title1.length > offset){ part = title1.substr(0, offset); $("#prev_title").text(part + dots); } if(title2.length > offset){ part = title2.substr(0, offset); $("#next_title").text(part + dots) } } else{ $("#prev_title").text(title1); $("#next_title").text(title2); } }, speed); }; $(document).ready(function () { titlelength(); }); </script><div class="utterance-light" id="comment_light"> <script src="https://utteranc.es/client.js" repo="junia3/comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div><div class="utterance-dark" id="comment_dark"> <script src="https://utteranc.es/client.js" repo="junia3/comments" issue-term="pathname" theme="github-dark" crossorigin="anonymous" async> </script></div><footer id="footer"> <!--Footer Button--><div class="container has-text-centered has-background-grey-darker" id="backtotop"> <a class="has-text-white" onclick="window.scroll(0,0)">BACK TO TOP</a></div><!--Footer Main Section--><div class="has-background-grey-darker"><div class="container columns"> <!--Name Section--><div class="column has-text-left-desktop has-text-centered-mobile"> <a href="http://localhost:4000/#about"><div class="columns"><div class="column is-one-fifth-desktop is-one-fifth-fullhd is-one-quarter-tablet"><figure class="image is-64x64"> <img class="is-rounded" src="https://avatars.githubusercontent.com/u/79881119?v=4"></figure></div><div class="column is-marginless"><h5 class="has-text-grey-lighter">JY</h5><div class="content has-text-grey"><p>I am an AI researcher with a strong interest in machine learning and dee...</p></div></div></div></a></div><!--Link Section--><div class="column has-text-white"><h3>More Links</h3><li> <a href="http://localhost:4000/category/development">DEVELOPMENT</a></li><li> <a href="http://localhost:4000/category/github%20blog">GITHUB BLOG</a></li><li> <a href="http://localhost:4000/category/paper%20review">PAPER REVIEW</a></li></div><!--Blog-post Section--><div class="column has-text-white"><h3>Recent Posts</h3><li> <a href="http://localhost:4000/blog/deepseekr1">딥시크(Deepseek)-R1에 대한 고찰. Thinking about Deepseek-R1 with Reinforcement Learning(RL).</a></li><li> <a href="http://localhost:4000/blog/mamba">Mamba modeling의 기초 (3) - Linear-Time Sequence Modeling with Selective State Spaces (Mamba)에 대하여</a></li><li> <a href="http://localhost:4000/blog/s4">Mamba modeling의 기초 (2) - (S4) Efficiently Modeling Long Sequences with Structured State Spaces에 대하여</a></li></div></div></div><div class="has-background-black has-text-centered has-text-white" id="credits"></div></footer></body></html><script> $(window).scroll(function() { var scrollY = ($(window).scrollTop() / ($(document).height() - $(window).height()) * 100).toFixed(3); $(".bar").css({"width" : scrollY + "%"}); }); </script>
